<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[通过list()和[]创建空列表的差异]]></title>
    <url>%2F2019%2F05%2F22%2F%E9%80%9A%E8%BF%87list-%E5%92%8C-%E5%88%9B%E5%BB%BA%E7%A9%BA%E5%88%97%E8%A1%A8%E7%9A%84%E5%B7%AE%E5%BC%82%2F</url>
    <content type="text"><![CDATA[我们想创建一个空列表，可以使用如下两种方式： 12345# option Aempty_list = list()# option Bempty_list = [] 但你有没有想过它们之间在效率上会不会有什么不同呢？我们应该优先使用哪种方式呢？ 最近，看文章碰到了这个问题，就研究了一下，通过命令测试下它们的效率，结果如图 可以看到通过 [] 创建列表明显要比 list() 快，这是为什么呢？ 用 list() 方法构造一个空列表使用的是 class list([iterable]) 的类型构造器，参数可以是一个iterable，如果没有给出参数，构造器将创建一个空列表 []，相比较而言多了一步 class 调用和参数判断，所以用 [] 直接构造一个空列表的方法速度更快。 简而言之，主要的区别在于 list() 是一个 function call，Python 的 function call 会创建 stack，并且进行一系列参数检查的操作，中间的开销相对而言就更大了，而 [] 是一个内置的 C 函数，可以直接被调用，因此效率高。 PS：字典（dict）、元组（tuple）等的创建也是如此。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>内部探究</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Huey 每日定时任务的坑]]></title>
    <url>%2F2019%2F05%2F16%2FHuey-%E6%AF%8F%E6%97%A5%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[最近别人推荐了个轻量级任务队列 Huey，然后我就去试了下，挺好用的，但却碰了文档未说明的坑。 我要做一个每日执行一次的任务，文档只给出每三分钟执行一次的例子： 123456789from huey import SqliteHueyfrom huey import crontabhuey = SqliteHuey(filename='/tmp/demo.db')@huey.periodic_task(crontab(minute='*/3'))def every_three_minutes(): print('This task runs every three minutes') 我以为每日执行一次可以这样写： 123@huey.periodic_task(crontab(day='*/1'))def print_in_a_day(): print('-- PERIODIC TASK -- THIS RUNS EVERY 1 DAYS --') 结果它每一分钟就执行了一次，我：？？？ 最后发现还需要设置执行小时和分钟： 123@huey.periodic_task(crontab(day='*/1', hour='0', minute='0'))def print_in_a_day(): print('-- PERIODIC TASK -- THIS RUNS EVERY 1 DAYS --')]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Huey</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 的 Context 机制]]></title>
    <url>%2F2019%2F03%2F25%2FFlask-%E7%9A%84-Context-%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[一文带你全面理解 Flask 的 Context 机制。 使用过 Flask 进行 Web 开发的同学应该知道 App Context 和 Request Context 这两个非常有特色的设计。1 从一个 Flask App 读入配置并启动开始, 就进入了 App Context, 在其中我们可以访问配置文件、打开资源文件、通过路由规则反向构造 URL。当一个请求进入开始被处理时, 就进入了 Request Context, 在其中我们可以访问请求携带的信息, 比如 HTTP Method、表单域等。 最近闲着没什么事做, 研究了一番这两个 Context 的具体实现, 同时还解决了一些自己之前“知道结论不知道过程”的疑惑, 所以撰写本文记录下来。 Thread Local 的概念在面向对象的设计中, 对象是保存”状态”的地方。Python 也是如此, 一个对象的状态都被保存在对象携带的一个特殊字典(__dict__)中, 可以通过vars函数拿到它。 Thread Local 则是一种特殊的对象, 它的”状态”对线程隔离——也就是说每个线程对 Thread Local 对象的修改都不会影响到其他线程。这种对象的实现原理也非常简单, 只要以线程的 ID 来保存多份状态字典即可, 就像按照门牌号隔开的信箱。 在 Python 中获得一个这样的 Thread Local 最简单的方法是threading.local:1234567891011121314151617import threadingstorage = threading.local()storage.foo = 1print(storage.foo)class AnotherThread(threading.Thread): def run(self): storage.foo = 2 # storage.foo 在这个线程中已经发生改变 print(storage.foo)another = AnotherThread()another.start()# 但是在主线程里并没有改变print(storage.foo) 这样来说, 只要能构造出 Thread Local 对象, 就能够让同一个对象在多个线程下做到状态隔离。这个”线程”不一定要是系统线程, 也可以是用户代码中的其他调度单元, 例如 Greenlet。 Werkzeug 实现的 Local Stack 和 Local ProxyWerkzeug 没有直接使用threading.local, 而是自己实现了werkzeug.local.Local类。后者和前者有一些区别: Werkzeug 实现的 Local 类会在 Greenlet 可用的情况下优先使用 Greenlet 的 ID 而不是线程 ID 以支持 Gevent 或者 Eventlet 的调度, 而threading.local只支持多线程调度; Werkzeug 的 Local 类实现了 Werkzeug 自定义的协议方法__release_local__, 可以被 Werkzeug 自己的release_local函数释放掉当前线程下的状态, 而threading.local没有这个能力。 除 Local 外, Werkzeug 还实现了两种数据结构：LocalStack 和 LocalProxy。 LocalStack 是用 Local 实现的栈结构, 可以将对象推入、弹出, 也可以快速拿到栈顶对象。当然, 所有的修改都只在本线程可见。和 Local 一样, LocalStack 也同样实现了支持 release_local 的接口。 LocalProxy 则是一个典型的代理模式实现, 它在构造时接受一个 callable 的参数（比如一个函数）, 这个参数被调用后的返回值本身应该是一个 Thread Local 对象。对一个 LocalProxy 对象的所有操作, 包括属性访问、方法调用（当然方法调用就是属性访问）甚至是二元操作都会转发到那个 callable 参数返回的 Thread Local 对象上。 LocalProxy 的一个使用场景是 LocalStack 的__call__方法。例如, my_local_stack是一个 LocalStack 实例, 那么调用my_local_stack()会返回一个 LocalProxy 对象, 这个对象始终指向my_local_stack的栈顶元素。如果栈顶元素不存在, 访问这个 LocalProxy 对象会抛出RuntimeError。 Flask 基于 LocalStack 的 ContextFlask 是一个基于 Werkzeug 实现的框架, 所以 Flask 的 App Context 和 Request Context 也理所当然地基于 Werkzeug 的 Local Stack 实现。 在概念上, App Context 代表了”应用级别的上下文”, 比如配置文件中数据库的连接信息; Request Context 代表了”请求级别的上下文”, 比如当前访问的 URL。 这两个上下文对象的类定义在flask.ctx中, 它们的用法是将应用上下文和请求上下文推入推出到flask.globals中创建的_app_ctx_stack和_request_ctx_stack这两个 LocalStack 单例中。 因为 LocalStack 的状态是线程隔离的, 而 Web 应用中每个线程(或者 Greenlet)同时只能处理一个请求, 所以 App Context 对象和 Request Context 对象在请求中也是隔离的。 当app = Flask(__name__)构造出一个 Flask App 时, App Context 并不会自动被推入 Stack 中。所以此时 Local Stack 的栈顶是空的, current_app也是 unbound 状态。 123456789101112&gt;&gt;&gt; from flask import Flask&gt;&gt;&gt; from flask.globals import _app_ctx_stack, _request_ctx_stack&gt;&gt;&gt;&gt;&gt;&gt; app = Flask(__name__)&gt;&gt;&gt; _app_ctx_stack.top&gt;&gt;&gt; _request_ctx_stack.top&gt;&gt;&gt; _app_ctx_stack()&lt;LocalProxy unbound&gt;&gt;&gt;&gt;&gt;&gt;&gt; from flask import current_app&gt;&gt;&gt; current_app&lt;LocalProxy unbound&gt; 这也是 Flask 的一些使用者可能被坑的地方——比如编写一个离线脚本时, 如果直接在一个 Flask-SQLAlchemy 写成的 Model 上调用User.query.get(user_id), 就会遇到RuntimeError。因为此时 App Context 还没被推入栈中, 而 Flask-SQLAlchemy 需要数据库连接信息时, 就会去current_app.config中获取, current_app指向的却是_app_ctx_stack为空的栈顶。 解决办法是运行脚本之前, 先将 App 的 App Context 推入栈中, 栈顶不为空后, current_app这个 LocalProxy 对象自然能将”取 config 属性”这个动作转发到当前的 App 上。 12345678910111213&gt;&gt;&gt; ctx = app.app_context()&gt;&gt;&gt; ctx.push()&gt;&gt;&gt; _app_ctx_stack.top&lt;flask.ctx.AppContext object at 0x102eac7d0&gt;&gt;&gt;&gt; _app_ctx_stack.top is ctxTrue&gt;&gt;&gt; current_app&lt;Flask '__main__'&gt;&gt;&gt;&gt;&gt;&gt;&gt; ctx.pop()&gt;&gt;&gt; _app_ctx_stack.top&gt;&gt;&gt; current_app&lt;LocalProxy unbound&gt; 那么为什么在应用运行时不需要手动调用app_context().push()呢? 因为 Flask App 作为 WSGI Application 运行时, 会在每个请求进入的时候将请求上下文推入_app_ctx_stack中, 而请求上下文一定是在应用上下文中的, 所以推入部分的逻辑有这样一条: 如果发现_app_ctx_stack为空, 则隐式的推入一个 App 上下文。 所以, 请求中是不需要手动推上下文入栈的, 但是离线脚本需要手动推入上下文。 两个疑问这里还有两个疑问需要处理: 为什么 App Context 需要独立出来: 既然在 Web 应用运行时, App Context 和 Request Context 都是 Thread Local 对象, 那么为什么还要独立区分二者呢? 为什么要放在”栈”里: 在 Web 应用运行时, 一个线程同时只能处理一个请求, 那么_app_ctx_stack和_request_ctx_stack栈顶肯定只有一个元素, 为什么还要用栈这种结构呢? 这两个做法给予我们多个 Flask App 共存和非 Web 应用运行时灵活控制 Context 的可能性。 在对一个 Flask App 调用app.run()之后, 进程就进入阻塞模式并开始监听请求。此时是不可能让另一个 Flask App 在主线程运行起来的, 那么还有哪些场景需要多个 Flask App 共存呢? 之前说过 Flask App 实例就是一个 WSGI Application, 而 WSGI Middleware 是允许使用组合模式的, 比如:12345from werkzeug.wsgi import DispatcherMiddlewarefrom your_application import appfrom your_application.admin import app as admin_appapplication = DispatcherMiddleware(app, &#123;'/admin': admin_app&#125;) 这个例子就是使用 Werkzeug 内置的 Middleware 将两个 Flask App 组合成一个 WSGI Application。这种情况下两个 App 都同时在运行, 只是根据请求 URL 的不同将请求分发到不同的 App 上进行处理。 需要注意的是, 这种用法和 Flask 的 Blueprint 是有区别的。Blueprint 虽然和这种用法很类似, 但 Blueprint 自己是没有 App Context 的, 只是同一个 Flask App 内部资源共享的一种方式, 所以多个 Blueprint 共享了同一个 Flask App; 而使用 Middleware 面向的是所有的 WSGI Application, 不仅仅是 Flask App, 即使是把 Django App 和 Flask App 用这种方式组合起来也是可行的。 在非 Web 环境运行 Flask 关联的代码设想, 一个离线脚本需要操作两个甚至多个 Flask App 关联的上下文, 应该怎么办呢? 这时候栈结构的 App Context 的优势就展现出来了。123456789101112from your_application import create_appfrom your_application.admin import create_app as create_admin_appapp = create_app()admin_app = create_admin_app()def copy_data(): with app.app_context(): data = read_data() with admin_app.app_context(): write_data(data) mark_data_copied() 无论有多少个 App, 只要主动去 push 它的 App Context, Context Stack 中就会累计起来。这样, 栈顶永远是当前操作的 App Context, 当一个 App Context 结束的时候, 相应的栈顶元素也随之出栈。如果在执行过程中抛出了异常, 对应的 App Context 中注册的teardown函数被传入带有异常信息的参数。 这么一来就解释了之前的两个疑问——在这种单线程运行环境中, 只有栈结构才能保存多个 Context 并在其中定位出哪个才是”当前”。而离线脚本只需要 App 关联的上下文, 不需要构造出请求, 所以 App Context 也应该和 Request Context 分离。 1.Flask 的官方文档也对 App Context 和 Request Context 作出了详细的解释。 ↩]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[帮助理解encode和decode的小技巧]]></title>
    <url>%2F2018%2F11%2F29%2F%E5%B8%AE%E5%8A%A9%E7%90%86%E8%A7%A3encode%E5%92%8Cdecode%E7%9A%84%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[最近公司业务需要做网络数据包处理，总是被字符的编码和解码折磨，一直以来我也不怎么搞得清楚什么时候该用.encode(), 什么时候该用.decode()。 现在发现了一个简单的方法，可帮助自己记住.encode()和.decode()的区别: 可以把字节序列想成晦涩难懂的机器码，把 Unicode 字符想象成“人类可读”的文本，那么，把字节序列变成人类可读的文本字符串就是解码，而把字符串变成用于存储或传输的字节序列就是编码。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python函数传参问题]]></title>
    <url>%2F2018%2F11%2F28%2FPython%E5%87%BD%E6%95%B0%E4%BC%A0%E5%8F%82%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Python 唯一支持的参数传递模式是共享传参(call for sharing)。共享传参是指函数的各个形式参数获得实参中各个引用的副本，也就是说，函数内部的形参是实参的别名。 这种方案的结果是，函数可能会修改作为参数传入的可变对象，但是无法修改那些对象的标示(即不能把一个对象替换成另一个对象)。示例如下: 12345678910111213141516171819202122232425262728293031323334In [1]: def f(a, b): ...: a += b ...: return a ...: In [2]: x = 1In [3]: y = 2In [4]: f(x, y)Out[4]: 3In [5]: x, yOut[5]: (1, 2)In [6]: a = [1, 2]In [7]: b = [3, 4]In [8]: f(a, b)Out[8]: [1, 2, 3, 4]In [9]: a, bOut[9]: ([1, 2, 3, 4], [3, 4])In [10]: t = (10, 20)In [11]: u = (30, 40)In [12]: f(t, u)Out[12]: (10, 20, 30, 40)In [13]: t, uOut[13]: ((10, 20), (30, 40)) 简单说明一下: 示例中是一个简单的函数，它在参数上调用+=运算符，分别把数字、列表和元组传给这个函数，实际传入的参数会以不同的方式受到影响。 函数传参既不是传值也不是传引用上面已经对函数给出了结论，这里来对共享传参考进行具体说明。 对于函数传参的问题，基本上有三种观点: 传引用 传值 可变对象传引用，不可变对象传值 这三个观点到底哪个正确呢？我们逐一进行讨论。 传引用1234567891011121314&gt;&gt;&gt; def inc(n):... print(id(n))... n = n + 1... print(id(n))... &gt;&gt;&gt; n = 3&gt;&gt;&gt; id(n)4418535520&gt;&gt;&gt; inc(n)4418535520 # 修改之前的 n 的 id 值4418535552 # 修改之后的 n 的 id 值&gt;&gt;&gt; print(n)3&gt;&gt;&gt; 按照传引用的概念，上面的例子输出应该是 4，并且 inc() 函数里面执行操作 n = n + 1 的前后 n 的 id 值应该是不变的。可是事实是不是这样的呢？ 从输出的结果来看 n 的值还是不变，但 id(n) 的值在函数体前后却不一样。显然，传引用这个说法是不恰当的。 传值12345678910111213141516&gt;&gt;&gt; def change_list(orginator_list):... print('orginator list is: ', orginator_list)... new_list = orginator_list... new_list.append('I am new item')... print('new list is: ', new_list)... return new_list... &gt;&gt;&gt; orginator_list = ['a', 'b', 'c']&gt;&gt;&gt; new_list = change_list(orginator_list)orginator list is: ['a', 'b', 'c']new list is: ['a', 'b', 'c', 'I am new item']&gt;&gt;&gt; orginator_list['a', 'b', 'c', 'I am new item']&gt;&gt;&gt; new_list['a', 'b', 'c', 'I am new item']&gt;&gt;&gt; 传值通俗来讲就是这个意思: 你在内存中有一个位置，我也有一个位置，我把我的值复制给你，以后你做什么就跟我没关系了，你我之间井水不犯河水。可是上面的程序输出根本不是这么一回事，显示change_list()函数没有遵守约定，调用该函数之后orginator_list也发生了改变，这明显侵犯了orginator_list的权利。这么看来传值这个说法也不合适。 可变对象传引用，不可变对象传值。从上面的例子看来这个说法最靠谱，很多人也是这么理解的，但这个是否真的准确呢？再来看一个示例。12345678910111213&gt;&gt;&gt; def change_me(org_list):... print(id(org_list))... new_list = org_list... print(id(new_list))... if len(new_list) &gt; 5:... new_list = ['a', 'b', 'c']... for i, e in enumerate(new_list):... if isinstance(e, list):... new_list[i] = '***' # 将类型为 list 类型的元素替换为 ***... print(new_list)... print(id(new_list))... &gt;&gt;&gt; 传入的参数 org_list 为列表，属于可变类型，按照可变对象传引用的理解，new_list 和 org_list 指向同一块内存，因此两者的 id 值输出一致，任何对 new_list 所执行的内容的操作会直接反应到 org_list，也就是说修改 new_list 会导致 org_list 的直接修改，那么，接下来看看测试的例子:12345678910111213141516&gt;&gt;&gt; test1 = [1, ['a', 1, 3], [2, 1], 6]&gt;&gt;&gt; change_me(test1) # test1 的元素个数小于 544210035924421003592[1, '***', '***', 6] # test1 中所有 list 类型的元素都被替换成了 ***4421003592&gt;&gt;&gt; test1[1, '***', '***', 6]&gt;&gt;&gt; test2 = [1, 2, 3, 4, 5, 6, [1]] # test2 中的元素个数大于 5&gt;&gt;&gt; change_me(test2)44206654164420665416['a', 'b', 'c']4421780808&gt;&gt;&gt; test2 # test2 并没有发生改变[1, 2, 3, 4, 5, 6, [1]] 对于 test1、new_list 和 org_list 的表现和我们理解的传引用确实是一致的，最后 test1 被修改为 [1, ‘***‘, ‘***‘, 6]，但对于输入的 test2、new_list 和 org_list 的 id 输出在进行列表相关的操作前是一致的，但操作之后 new_list 的 id 却变为了 4421780808，整个 test2 在调用函数 change_me 后却没有发生任何改变，可是按照传引用的理解，期望的输出应该是 [‘a’, ‘b’, ‘c’]，似乎可变对象传引用这个说法也不恰当。 那么 Python 函数中参数传递的机制到底是怎么样的呢？要明白这个概念，首先要理解: Python 中的赋值与我们所理解的 C/C++ 等语言中的意思并不一样。 如果有如下语句:1a = 5, b = a, b = 7; 我们分别来看一下在 C/C++ 以及 Python 中是如何赋值的。如图所示，C/C++ 中当执行 b=a 的时候，在内存中申请一块内存并将 a 的值复制到该内存中；当执行 b=7 之后是将 b 对应的值从 5 修改为 7。 但在 Python 中赋值并不是复制，b=a 操作使得 b 与 a 引用同一个对象。而 b=7 则是将 b 指向对象 7，如下图所示: 我们通过以下示例来验证上面所述的过程:1234567891011&gt;&gt;&gt; a = 5&gt;&gt;&gt; id(a)4418535584&gt;&gt;&gt; b = a&gt;&gt;&gt; id(b) # b = a 之后 b 的 id 值和 a 一样4418535584&gt;&gt;&gt; b = 7&gt;&gt;&gt; id(b) # b = 7 之后，b 指向对象 7，id 值发生改变4418535648&gt;&gt;&gt; id(a)4418535584 从输出可以看到，b = a 赋值后 b 的 id() 输出和 a 一样，但进行 b = 7 操作后，b 指向另外一快空间。可以简单的理解为，b = a 传递的是对象的引用，其过程类似于贴“标签”，5 和 7 是实实在在的内存空间，执行 a = 5 相当于申请一块内存空间代表对象 5，然后在上面贴上标签a，这样 a 和 5 便绑定到一起了。而 b = a 相当于对对象 5 再次贴上了标签 b，因此 a 和 b 实际都指向了 5。b = 7 操作之后，标签b重新贴到 7 所代表的对象上去了，而此时 5 仅有标签 a。 理解了上面的背景，再重新回过头来看前面的例子就很好理解了。对于传值的例子，n = n + 1，由于 n 为数字，是不可变对象，n + 1 会重新申请一块内存，并将变量 n 指向它。当调用完函数 inc(n) 之后，函数体中的局部变量在函数外并不可见，此时的 n 代表函数外面的命名空间中所对应的 n，值还是 3。而在“可变对象传引用，不可变对象传值”的例子中，当 org_list 的长度大于 5 的时候，new_list = [‘a’, ‘b’, ‘c’] 操作重新创建了一块内存并将 new_list 指向它。当传入参数为 test2 = [1, 2, 3, 4, 5, 6, [1]] 的时候，函数的执行并没有改变该列表的值。 因此，对于 Python 函数参数传递的是值还是引用的问题的答案是: 都不是。正确的叫法应该是传对象或者说传对象的引用。函数参数在传递过程中将整个对象传入，对可变对象的修改在函数外部以及内部都可见，调用者和被调用者之间共享这个对象；而对于不可变对象，由于并不能真正的被修改，一次，修改往往是通过生成一个新的对象然后赋值来实现的。 不要使用可变类型作为参数的默认值可选参数可以有默认值，这是 Python 函数定义的一个很棒的特性，这样我们的 API 在进化的同时能保证向后兼容，然而，我们应该避免使用可变的对象作为参数的默认值。示例如下:1234567891011121314151617181920212223242526272829303132class HauntedBus: def __init__(self, passengers=[]): self.passengers = passengers def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) 运行结果:&gt;&gt;&gt; bus1 = HauntedBus(['Alice', 'Bill'])&gt;&gt;&gt; bus1.passengers['Alice', 'Bill']&gt;&gt;&gt; bus1.pick('Charlie')&gt;&gt;&gt; bus1,drop('Alice')&gt;&gt;&gt; bus1.passengers['Bill', 'Charlie']&gt;&gt;&gt; bus2 = HauntedBus()&gt;&gt;&gt; bus2.pick('Carrie')&gt;&gt;&gt; bus2.passengers['Carrie']&gt;&gt;&gt; bus3 = HauntedBus()&gt;&gt;&gt; bus3.passengers['Carrie']&gt;&gt;&gt; bus3.pick('Dave')&gt;&gt;&gt; bus2.passengers['Carrie', 'Dave']&gt;&gt;&gt; bus2.passengers is bus3.passengersTrue&gt;&gt;&gt; bus1.passengers['Bill', 'Charlie'] 这是因为 self.pasengers 变成了 passengers 参数默认值的别名，出现这个问题的根源是: 默认值在定义函数时计算（通常是加载模块时)，因此默认值变成了函数对象对象的属性。因此，如果默认值是可变对象，而且修改了它的值，那么后续的函数调用都会受到影响。 在运行完上面的代码后，可以审查 HauntedBus.__init__ 对象，看看它的__defaults__属性中的那些值:1234&gt;&gt;&gt; dir(HauntedBus.__init__)['__annotations__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', ... ]&gt;&gt;&gt; HauntedBus.__init__.__defaults__(['Carrie', 'Dave'],) 最后，我们可以验证 bus2.passengers 是一个别名，它绑定到 HauntedBus.__init__.__defaults__属性的第一个元素上:12&gt;&gt;&gt; HauntedBus.__init__.__defaults__[0] is bus2.passengersTrue 可变默认值导致的这个问题说明了为什么通常使用 None 作为接受可变值的参数的默认值。如下所示:123456789101112class Bus: def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers) def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) 防御可变参数如果定义的函数接受可变参数，应该谨慎考虑调用方是否期望修改传入的参数。 例如，如果函数接受一个字典，而且在处理的过程中要修改它，那么这个副作用要不要体现到函数外部？具体情况具体分析。这其实需要函数的编写者和调用方达成共识。 在下面这个示例中，TwilightBus 实例与客户共享乘客列表，这回产生意料之外的结果。123456789101112131415161718192021class TwilightBus: def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = passengers def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name)basketball_team = ['Sue', 'Tina', 'Maya', 'Diana', 'Pat']bus = TwilightBus(basketball_team)bus.drop('Tina')bus.drop('Pat')# basketball_team的内容print(baskekball_team)out: ['Sue', 'Maya', 'Diana'] TwilightBus 违反了设计接口的最佳实践，即“最少惊讶原则(Principle of least astonishment)”。篮球队员从校车中下车后，名字就从篮球队的名单中消失了，这确实让人惊讶。 这里的问题是，校车为传给构造方法的列表创建了别名。正确的做法是，校车自己维护乘客的列表，修正的方法很简单: 在__init__方法中，传入 passengers 参数时，应该把参数值的副本赋值给 self.passengers，如下所示:12345def __init__(self, passengers): if passengers is None: self.passengers = [] else: self.passengers = list(passengers) 在内部像这样处理乘客列表，就不会影响初始化校车时传入的参数了。此外，这种处理方式还更灵活: 现在，传给 passengers 参数的值可以是元组或任何其他可选迭代对象，例如set对象，甚至数据库查询结果，因为list构造方法接受任何可迭代对象。自己创建并管理列表可以确保支持所需的.remove()和.append()操作，这样.pick()和.drop()方法才能正常运作。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL死锁检测中热点行更新导致的性能问题]]></title>
    <url>%2F2018%2F11%2F28%2FMySQL%E6%AD%BB%E9%94%81%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%83%AD%E7%82%B9%E8%A1%8C%E6%9B%B4%E6%96%B0%E5%AF%BC%E8%87%B4%E7%9A%84%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[有一个电影票在线交易业务，顾客 A 要在影院 B 购买电影票。这个业务涉及到以下操作： 从顾客 A 的账户余额中扣除电影票价； 给影院 B 的账户余额中增加这张电影的票价； 记录一条交易日志。 也就是说，要完成这个交易，我们需要 update 两条记录，并 insert 一条记录。当然，为了保证交易的原子性，我们要把这三个操作一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？ 试想如果同时有另一个顾客 C 要在影院 B 买票，那么这两个事务冲突的部分就是语句 2 了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。 根据两阶段锁协议，不论怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句 2 安排在最后，比如按照 3、1、2 这样的顺序执行，那么影院账户余额这一行的锁时间就最少。这样就最大程度地减少了事务之间的锁等待，提高了并发度。 如果这个影院做活动，可以低价预售一年之内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的 MySQL 就挂了。登上服务器一看，CPU 消耗接近 100%，但整个数据库每秒就只执行不到 100 个事务。这是什么原因呢？这里就要说到死锁和死锁检测了。 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。示例如下: 事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。 当死锁出现后，有两种解决策略： 直接进入等待状态，直到超时。这个超时的时间可以通过参数innodb_lock_wait_timeout来设置。 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为 on，表示开启这个逻辑。 在 InnoDB 中，innodb_lock_wait_timeout的默认值是 50s，意味着如果采用第一个策略，当出现死锁后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。 但是，我们又不能直接把这个时间设置成一个很小的值，比如 1s，这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以超时时间设置的太短的话，会出现很多的误伤。 所以正常情况下，我们还是要采取第二种策略，即: 主动死锁检测，而且innodb_deadlock_detect参数的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是额外负担的。 可以想象以下这个过程: 每当出现一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。 这里就可以回到我们上面说的那个问题了。 每个新来的被堵住的线程，都要判断会不会由于自己的加入而导致了死锁，这是一个时间复杂度为 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此就会出现 CPU 利用率很高，但是每秒却执行不了几个事务。 根据上面的分析，我们该怎样解决这种热点行更新导致的性能问题呢? 问题的结症在与死锁检测要耗费大量的 CPU 资源。 一种头疼医头、脚疼医脚的方法就是如果能确保这个业务一定不会出现死锁，可以临时把死锁检测给关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当作一个严重的错误，毕竟出现了死锁，就回滚，然后通过业务重试，一般就没问题了，这是业务无损的，而关掉死锁检测意味着可能会出现大量的超时，这是有损的。 另一个思路是控制并发度。根据上面的分析，如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么进行死锁检测的成本很低，就不会出现这个问题。 一个直接的想法就是在客户端做并发控制，但是这个方法不太可行，因为客户端很多，比如：一个应用有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能会达到 3000。​因此，这个并发控制要实现在数据库服务端。如果有中间件，可以考虑在中间价中实现; 如果团队有能修改 MySQL 源码的人，也可以在 MySQL 里面实现。 基本思路就是: 对于相同行的更新，在进入引擎之前进行排队，这样在 InnoDB 内部就不会有大量的死锁检测工作了。 但是如果团队里暂时没有数据库方面的专家，不能实现这样的方案，可以考虑从设计上优化这个问题: 可以考虑通过将一行改成逻辑上的多行来减少锁冲突，以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 条记录的值的总和。每次要给影院账户加金额的时候，随机选其中一条记录来加，这样每次冲突的概率就变成原来的 1/10，可以减少锁等待的个数，也就减少了死锁检测的 CPU 消耗。 这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额减少，比如退票操作，这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊的处理。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在mysql如何挑选索引列]]></title>
    <url>%2F2018%2F11%2F27%2F%E5%9C%A8mysql%E5%A6%82%E4%BD%95%E6%8C%91%E9%80%89%E7%B4%A2%E5%BC%95%E5%88%97%2F</url>
    <content type="text"><![CDATA[为用于搜索、排序或分组的列创建索引，而对于用作输出显示的列则不用创建索引。这意味着最佳索引候选列是那些出现在 WHERE 子句中的列、连接子句中的列或者出现在 ORDER BY 或 GROUP BY 子句中的列。而那些只是出现在 SELECT 关键字后面的输出列表里的列，则不是很好的索引候选列。 认真考虑数据列基数。列的基数(cardinality)是指它所容纳的所有非重复值的个数，例如，某个列包含值 1、3、7、4、7、3，那么它的基数为 4。相对于表里面行的总数来说，列的基数越高(也就就是说，它包含的唯一值多，重复值少)，索引的使用效果越好。对于包含许多不同年龄值的列，索引可以很容易地将各个行区分开来。但是对于记录性别的列，其中只会包含两个值：’M’和’F’，索引操作毫无用处。如果这两个值出现的频率大致一样，那么不管搜索哪个值，你得到的都是近乎一半的行。在这种情况下，索引可能根本无法使用，因为当查询优化程序确定出某个值在表的行里出现频率很大时，它会跳过索引，直接执行全表扫描操作。 索引短小值。应该尽量选用较小的数据类型，较短小的值可以在一下几个方面提高索引的处理效率: 短小值可以让比较操作更快，从而加快索引查找速度。 短小值可以让索引短小，从而减少对磁盘 I/O 请求。 对于短小的键值，键缓存里的索引块可以容纳更多的键值。如果 MySQL 能在内存里容纳更多的键，那么就可以在不从磁盘读取更多索引块的前提下，提高找到键值的几率。 对 InnoDB 存储引擎，因为它使用的是聚簇索引（clustered index），所以让主键尽量短小会带来更多好处。聚簇索引会把数据行和主键值存储在一起(即聚集在一起)。其他的索引都是二级索引，即它们把主键值和二级索引值存储在一起。在二级索引里进行查找，会先得到主键值，然后再通过它在主键索引中定位到相应的行。ps: 该行为被称为回表操作。这意味着，主键值在每一个二级索引里都会重复出现，因此如果主键值较长，则会导致每一个二级索引需要占用更多的存储空间。 索引字符串的前缀。想要对字符串列进行索引，应当尽可能指定前缀长度。例如，有一个 CHAR(20) 列，如果大多数值的前 10 或 20 个字符都是唯一的，那么就可以不用为整个进行索引，而只为前面的 10 或 20 个字符进行索引，这样可以节省大量的索引空间，而且还能使索引变得更快。不过，只索引列的第一个字符恐怕不行，因为这样做会导致索引无法获得大量的唯一值。 利用最左前缀。当创建包含 n 个列的符合索引时，实际上会创建 n 个专供 MySQL 使用的索引。复合索引相当于多个索引，因为索引中最左边的任意数据列集合都可用于匹配各个行，这样的集合即为“最左前缀”。(这与对列的前缀进行索引有所不同，它会使用列值的前 n 个字符或字节来创建索引。) 不要建立过多的索引。不要以为索引“越多越好”，然后就为你所能看到的所有数据列都建立索引，这是因为每增加一个索引都需要占据额外的磁盘空间，而且都会影响写入操作的性能。在对表做了修改之后，索引就会更新，并且可能还会重组，索引越多，整个过程所占用的时间就越长。很少使用或从不使用索引，会大大降低表的修改速度。此外，在为检索生成执行计划时，MySQL 会对索引进行仔细推敲，创建多余的索引，会为查询优化程序增加更多的工作，当表有太多的索引时，MySQL 还有可能(只是存在可能)无法使用最好的索引。 让参与比较的索引类型保持匹配。在创建索引时，大部分存储存储引擎都会选择它们要使用的索引实现。例如，InnoDB 总会使用 B 树索引; MyISAM 也会使用 B 树索引，但对于空间类型则会改用 R 树索引; MEMORY 存储引擎默认会使用散列索引，但它也支持 B 树索引，并允许在这两者之间进行选择。 在选择索引类型时，请考虑计划在索引列上执行的是什么类型的比较操作: 对于散列索引，会有一个散列函数应用于每一个列值。最终的散列值都会被存入索引，用于执行查找。(散列函数的算法，会尽量为不同的输入值生成不同的散列值，使用散列值的好处是它们之间的比较比其原始值更有效率。) 在使用运算符=或&lt;=&gt;完成精度匹配的比较操作里，散列索引的速度非常快。但在那些用于查找一个范围内的值的比较操作里，它们却表现欠佳，如下列表达式:id &lt; 30 或者 weight BETWEEN 100 AND 150 在使用&lt;、&lt;=、=、&gt;=、&gt;、&lt;&gt;、!=和BETWEEN运算符，进行精确比较或范围比较时，使用 B 树索引会带来高效。如果匹配模式是以一个纯字符串，而不是一个通配符作为开头的，那么 B 树索引还可用在使用运算符LIKE进行模式匹配的操作里。 使用慢查询日志找出那些性能低劣的查询。这个日志可以帮助我们找出从索引当中获益的查询，慢查询日志是一个文本文件，它可以用任何文件显示程序打开查看，也可以用 mysqldumpslow 工具来汇总其内容。如果某个给定的查询在这个日志里频繁出现，那么这个查询可能就不是最优的，需要改写，以让它运行得更快。在查看慢查询日志时，请记住“慢”是实时测量出来的，因此，与处于低负载时相比，服务器处于高负载时，会往慢查询日志里写入更多的查询。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL中不同存储引擎的索引的实现方式]]></title>
    <url>%2F2018%2F11%2F25%2FMySQL%E4%B8%AD%E4%B8%8D%E5%90%8C%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%9A%84%E7%B4%A2%E5%BC%95%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[对于不同的 MySQL 存储引擎，索引的具体实现细节也有所不同。 对于 MyISAM 表，其数据行保存在数据文件中，而索引值则保存在索引文件里。一个表可以有多个索引，但它们都保存在同一个索引文件里。索引文件里的每一个索引都由一组有序的关键字行构成，这个组中的关键字行主要用于快速访问数据文件。 InnoDB 存储引擎没有按照上面的方法将行和索引值分开放置，尽管它也是把索引值当作是一组有序值。默认情况下，InnoDB 存储引擎只使用一个表空间，在这个表空间的内部，管理着所有 InnoDB 表的数据存储和索引存储。可以通过配置 InnoDB，让它创建的每个表都有自己的表空间，但即使如此，给定表的数据和索引也同样保存在同一个表空间文件里。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在数据库中为什么尽量不使用长事务?]]></title>
    <url>%2F2018%2F11%2F20%2F%E5%9C%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E4%B8%BA%E4%BB%80%E4%B9%88%E5%B0%BD%E9%87%8F%E4%B8%8D%E4%BD%BF%E7%94%A8%E9%95%BF%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这会导致大量的占用存储空间。 在 MySQL 5.5 及以前的版本中，回滚日志跟数据字典一起放在 ibdata 文件里面，即使长事务最终提交，回滚段被清理，文件也不会变小。 除了对回滚段有影响，长事务还占用锁资源，这也有可能会拖垮整个库。 如何避免长事务对业务的影响这个问题，我们可以从应用开发端和数据库端分开来看。 从应用端来看： 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。但有些业务并没有这个需要，但也把好几个 select 语句放到事务中。这种只读事务可以去掉。 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。 从数据库端来看 监控 information_schema.innodb_trx 表，设置长事务阀值，超过就报警或者 kill。 Percona 的 pt-kill 这个工具不错，推荐使用。 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题。 如果使用的是 MySQL 5.6 或者更高的版本，把 innodb_undo_tablespaces 设置成 2 (或者更大的值)。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模板模式]]></title>
    <url>%2F2018%2F10%2F31%2F%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[模板模式：抽象出算法公共部分从而实现代码复用。 编写优秀代码的一个要素是避免冗余。在面向对象编程中，方法和函数是我们用来避免编写冗余代码的重要工具。 模板设计模式旨在消除代码重复。如果我们发现结构相近的（多个）算法中有重复代码，则可以把算法的不变（通用）部分留在一个模板方法/函数中，把易变（不同）的部分移到动作/钩子方法/函数中。 实际上这种模式在代码重构的时候是经常使用的 ，这里以一个例子来进行说明: 首先安装cowpy(ps: 竟然有人编写这个)：1pip install cowpy 代码如下：1234567891011121314151617181920212223242526272829303132from cowpy import cowdef dots_style(msg): msg = msg.capitalize() msg = '.' * 10 + msg + '.' * 10 return msgdef admire_style(msg): msg = msg.upper() return '!'.join(msg)def cow_style(msg): msg = cow.milk_random_cow(msg) return msgdef generate_banner(msg, style=dots_style): print('-- start of banner --') print(style(msg)) print('-- end of banner --\n\n')def main(): msg = 'happy coding' [generate_banner(msg, style) for style in (dots_style, admire_style, cow_style)]if __name__ == "__main__": main() 运行结果：12345678910111213141516171819202122-- start of banner --..........Happy coding..........-- end of banner ---- start of banner --H!A!P!P!Y! !C!O!D!I!N!G-- end of banner ---- start of banner --______________&lt; happy coding &gt;-------------- o o ^__^ / (**)\_______/ _________ (__)\ )=( ____|_ \_____U ||----w | \ \ \_____ | || || || ||-- end of banner --]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[策略模式]]></title>
    <url>%2F2018%2F10%2F31%2F%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[策略模式是一种非常通用的设计模式，可应用的场景很多。一般来说，不论何时希望动态、透明地应用不同算法，策略模式都是可行之路。这里所说不同算法的意思是，目的相同但实现方案不同的一类算法。这意味着算法结果应该是完全一致的，但每种实现都有不同的性能和代码复杂性（举例来说，对比一下顺序查找和二分查找）。 策略模式的另一个应用是创建不同的样式表现，为了实现可移植性（例如，不同平台之间断行的不同）或动态地改变数据的表现。 另一个值得一提的应用是模拟；例如模拟机器人，一些机器人比另一些更有攻击性，一些机器人速度更快，等等。机器人行为中的所有不同之处都可以使用不同的策略来建模。 以排序算法为例子，挑选一个合适的排序算法的时候，需要考虑待排序数组的以下特征： 需要排序的元素数量。大部分排序算法在输入规模很小的时候效率相差不大，只有一部分O(nlogn)平均时间复杂度的算法适合大规模排序。 算法的最佳/平均/最差时间复杂度。这个往往是挑选排序算法时候优先考虑的。 算法的空间复杂度。是不是原地排序(inplace)，需要额外的空间吗？在内存限制苛刻的时候就需要考虑。 算法的稳定性。排序算法是稳定的吗？稳定是指相同大小的值排序后保持相对顺序。 实现复杂度。算法是否容易实现，其他大致相同的情况下，优先考虑易维护的代码。 示例：12345678910111213def f1(seq): pass def f2(seq): pass def f(seq): if len(seq) &gt;= threshold_value: # 大于某个阈值 f1(seq) # 在数量较多时候具有良好的效率 else: f2(seq)]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[状态模式]]></title>
    <url>%2F2018%2F10%2F30%2F%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[状态模式是一个或多个有限状态机（简称状态机）的实现，用于解决一个特定的软件工程问题。 状态机是一个抽象机器，具有两个主要部分：状态和转换。状态是指一个系统的当前状况。一个状态机在任意时间点只会有一个激活状态。转换是指从当前状态到一个新状态的切换。在一个转换发生之前或之后通常会执行一个或多个动作。状态机可以使用状态图进行视觉上的展现。 状态机用于解决许多计算机问题和非计算机问题，其中包括交通灯、停车计时器、硬件设计和编程语言解析等。 这里以一个计算机系统的进程实现状态机为例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106# 先装下pip3 install state_machinefrom state_machine import ( acts_as_state_machine, State, Event, before, after, InvalidStateTransition)@acts_as_state_machineclass Process: # 先来定义状态机的状态 states created = State(initial=True) # 初始状态 waiting = State() running = State() terminated = State() blocked = State() swapped_out_waiting = State() swapped_out_blocked = State() # 再定义状态机的转移 transitions wait = Event(from_states=(created, running, blocked, swapped_out_waiting), to_state=waiting) run = Event(from_states=waiting, to_state=running) terminate = Event(from_states=running, to_state=terminated) block = Event(from_states=(running, swapped_out_blocked), to_state=blocked) swap_wait = Event(from_states=waiting, to_state=swapped_out_waiting) swap_block = Event(from_states=blocked, to_state=swapped_out_blocked) def __init__(self, name): self.name = name # The state_machine module provides us with the @before and @after # decorators that can be used to execute actions before or after a # transition occurs, respectfully. @after('wait') def wait_info(self): print('&#123;&#125; entered waiting mode'.format(self.name)) @after('run') def run_info(self): print('&#123;&#125; is running'.format(self.name)) @before('terminate') def terminate_info(self): print('&#123;&#125; terminated'.format(self.name)) @after('block') def block_info(self): print('&#123;&#125; is blocked'.format(self.name)) @after('swap_wait') def swap_wait_info(self): print('&#123;&#125; is swapped out and waiting'.format(self.name)) @after('swap_block') def swap_block_info(self): print('&#123;&#125; is swapped out and blocked'.format(self.name))def transition(process, event, event_name): """ Args: process (Process obj): event (Event obj): wait, run, terminate... event_name (str): name of event """ try: event() except InvalidStateTransition: print('Error: transition of &#123;&#125; from &#123;&#125; to &#123;&#125; failed'.format( process.name, process.current_state, event_name))def state_info(process): """ 当前状态机的状态 """ print('state of &#123;&#125;: &#123;&#125;'.format(process.name, process.current_state))def main(): RUNNING = 'running' WAITING = 'waiting' BLOCKED = 'blocked' TERMINATED = 'terminated' p1, p2 = Process('process1'), Process('process2') [state_info(p) for p in (p1, p2)] print() transition(p1, p1.wait, WAITING) transition(p2, p2.terminate, TERMINATED) [state_info(p) for p in (p1, p2)] print() transition(p1, p1.run, RUNNING) transition(p2, p2.wait, WAITING) [state_info(p) for p in (p1, p2)] print() transition(p2, p2.run, RUNNING) [state_info(p) for p in (p1, p2)] print() [transition(p, p.block, BLOCKED) for p in (p1, p2)] [state_info(p) for p in (p1, p2)] print() [transition(p, p.terminate, TERMINATED) for p in (p1, p2)] [state_info(p) for p in (p1, p2)] if __name__ == "__main__": main()]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[观察者模式]]></title>
    <url>%2F2018%2F10%2F29%2F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[观察者模式用在当一个对象的状态变更需要通知其他很多对象的时候，比如rss订阅或者在社交网站上订阅某个频道的更新。事件驱动系统也是一种发布订阅模式，事件作为发布者，监听器作为订阅者，只不过这里多个事件监听器可以监听同一个事件。 我们这里实现一个“Data Formatter”来解释发布订阅模式，一种数据可以有多个格式化Formatter，当数据更新的时候，会通知所有的Formatter格式化新的数据。使用继承来实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class Publisher: def __init__(self): self.observers = [] def add(self, observer): if observer not in self.observers: self.observers.append(observer) else: print('Failed to add : &#123;&#125;').format(observer) def remove(self, observer): try: self.observers.remove(observer) except ValueError: print('Failed to remove : &#123;&#125;').format(observer) def notify(self): [o.notify_by(self) for o in self.observers]class DefaultFormatter(Publisher): def __init__(self, name): super().__init__() self.name = name self._data = 0 def __str__(self): return "&#123;&#125;: '&#123;&#125;' has data = &#123;&#125;".format( type(self).__name__, self.name, self._data) @property def data(self): return self._data @data.setter def data(self, new_value): try: self._data = int(new_value) except ValueError as e: print('Error: &#123;&#125;'.format(e)) else: self.notify() # data 在被合法赋值以后会执行notifyclass HexFormatter: """ 订阅者 """ def notify_by(self, publisher): print("&#123;&#125;: '&#123;&#125;' has now hex data = &#123;&#125;".format( type(self).__name__, publisher.name, hex(publisher.data)))class BinaryFormatter: """ 订阅者 """ def notify_by(self, publisher): print("&#123;&#125;: '&#123;&#125;' has now bin data = &#123;&#125;".format( type(self).__name__, publisher.name, bin(publisher.data)))if __name__ == "__main__": df = DefaultFormatter('test1') print(df) print() hf = HexFormatter() df.add(hf) df.data = 3 print(df) print() bf = BinaryFormatter() df.add(bf) df.data = 21 print(df)]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式:解释器模式]]></title>
    <url>%2F2018%2F10%2F28%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[解释器模式用于为高级用户和领域专家提供一个类编程的框架，但没有暴露出编程语言那样的复杂性。这是通过实现一个DSL来达到目的的。 DSL是一种针对特定领域、表达能力有限的计算机语言。 DSL有两类，分别是内部DSL和外部DSL。内部DSL构建在一种宿主编程语言之上，依赖宿主编程语言，外部DSL则是从头实现，不依赖某种已有的编程语言。解释器模式仅与内部DSL相关。 例如：乐谱是一个非软件DSL的例子。音乐演奏者像一个解释器那样，使用乐谱演奏出音乐。 我们可以使用Pyparsing创建一种DSL来控制大门（PS：使用一个好的解析工具以模式匹配来解释结果更加简单）。示例如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344from pyparsing import Word, OneOrMore, Optional, Group, Suppress, alphanumsclass Gate: def __init__(self): self.is_open = False def __str__(self): return 'open' if self.is_open else 'closed' def open(self): print('opening the gate') self.is_open = True def close(self): print('closing the gate') self.is_open = Falsedef main(): # 首先定义我们的DSL格式，我们这里最简单的控制语法就是 "open -&gt; gate" word = Word(alphanums) command = Group(OneOrMore(word)) token = Suppress("-&gt;") device = Group(OneOrMore(word)) argument = Group(OneOrMore(word)) event = command + token + device + Optional(token + argument) gate = Gate() cmds = ['open -&gt; gate', 'close -&gt; gate'] # 两个自定义的命令 open_actions = &#123;'gate': gate.open&#125; close_actions = &#123;'gate': gate.close&#125; for cmd in cmds: print(event.parseString(cmd)) # [['open'], ['gate']] cmd, dev = event.parseString(cmd) cmd_str, dev_str = ' '.join(cmd), ' '.join(dev) print(cmd_str, dev_str) if 'open' in cmd_str: open_actions[dev_str]() elif 'close' in cmd_str: close_actions[dev_str]()if __name__ == "__main__": main() 这样就实现了一个简单的大门控制语言，只是功能很弱。]]></content>
      <categories>
        <category>解释器模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>解释器模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之命令模式]]></title>
    <url>%2F2018%2F10%2F24%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[命令设计模式帮助我们将一个操作（撤销、重做、复制、粘贴等）封装成一个对象，通常是创建一个包含Operation所有逻辑和方法的类。 当我们去餐馆吃饭时，会叫服务员来点单。他们用来做记录的账单（通常是纸质的）就是命令模式的一个例子。在记录好订单后，服务员将其放入账单队列，厨师会照着单子去做。每个账单都是独立的，并且可用来执行许多不同命令，例如，一个命令对应一个将要烹饪的菜品。 通过命令模式可以控制命令的执行时间和过程，还可以用来组织事务。 这里用一些文件操作类来说明命令模式的使用:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import osverbose = Trueclass RenameFile: def __init__(self, path_src, path_dest): self.src, self.dest = path_src, path_dest def execute(self): if verbose: print("[renaming '&#123;&#125;' to '&#123;&#125;']".format(self.src, self.dest)) os.rename(self.src, self.dest) def undo(self): if verbose: print("[renaming '&#123;&#125;' back to '&#123;&#125;']".format(self.dest, self.src)) os.rename(self.dest, self.src)class CreateFile: def __init__(self, path, txt='hello world\n'): self.path, self.txt = path, txt def execute(self): if verbose: print("[creating file '&#123;&#125;']".format(self.path)) with open(self.path, mode='w', encoding='utf-8') as out_file: out_file.write(self.txt) def undo(self): delete_file(self.path)class ReadFile: def __init__(self, path): self.path = path def execute(self): if verbose: print("[reading file '&#123;&#125;']".format(self.path)) with open(self.path, mode='r', encoding='utf-8') as in_file: print(in_file.read(), end='')def delete_file(path): if verbose: print("deleting file '&#123;&#125;'".format(path)) os.remove(path)def main(): orig_name, new_name = 'file1', 'file2' commands = [] for cmd in CreateFile(orig_name), ReadFile(orig_name), RenameFile(orig_name, new_name): commands.append(cmd) [c.execute() for c in commands] answer = input('reverse the executed commands? [y/n] ') if answer not in 'yY': print("the result is &#123;&#125;".format(new_name)) exit() for c in reversed(commands): try: c.undo() except AttributeError as e: passif __name__ == '__main__': main()]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之责任链模式]]></title>
    <url>%2F2018%2F10%2F23%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[责任链（Chain of Responsibility）模式用于让多个对象来处理单个请求，或者用于预先不知道应该由哪个对象（来自某个对象链）来处理某个特定请求。我们可以使用计算机网络的广播来类比责任链模式。 在责任链模式中，发送方可直接访问链中的首个节点。若首个节点不能处理请求，则转发给下一个节点，如此直到请求被某个节点处理或者整个链遍历结束。这种设计模式用于实现发送方与接收方（多个）之间的解耦。 这里以一个事件驱动的例子来做说明：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class Event: def __init__(self, name): self.name = name def __str__(self): return self.nameclass Widget: """Docstring for Widget. """ def __init__(self, parent=None): self.parent = parent def handle(self, event): handler = 'handle_&#123;&#125;'.format(event) if hasattr(self, handler): method = getattr(self, handler) method(event) elif self.parent: self.parent.handle(event) elif hasattr(self, 'handle_default'): self.handle_default(event)class MainWindow(Widget): def handle_close(self, event): print('MainWindow: &#123;&#125;'.format(event)) def handle_default(self, event): print('MainWindow: Default &#123;&#125;'.format(event))class SendDialog(Widget): def handle_paint(self, event): print('SendDialog: &#123;&#125;'.format(event))class MsgText(Widget): def handle_down(self, event): print('MsgText: &#123;&#125;'.format(event))def main(): mw = MainWindow() sd = SendDialog(mw) # parent是mw msg = MsgText(sd) for e in ('down', 'paint', 'unhandled', 'close'): evt = Event(e) print('\nSending event -&#123;&#125;- to MainWindow'.format(evt)) mw.handle(evt) print('Sending event -&#123;&#125;- to SendDialog'.format(evt)) sd.handle(evt) print('Sending event -&#123;&#125;- to MsgText'.format(evt)) msg.handle(evt)if __name__ == "__main__": main()]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之代理模式]]></title>
    <url>%2F2018%2F10%2F22%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[代理模式是通过一层间接保护层实现更安全的接口访问，例如：访问敏感信息——在允许用户访问敏感信息之前，我们希望确保用户具备足够的权限。 有四种常用的代理模式： 远程代理：实际存在于不同地址空间（例如，某个网络服务器）的对象在本地的代理者。使得访问远程对象就像访问本地一样，隐藏了复杂性，如：ORM。 虚拟代理：用来实现延迟访问，比如一些需要复杂计算的对象，Python 里可以实现 lazy_property，改善性能。 保护/防护代理：用于控制敏感对象的访问。 智能(引用)代理：在对象被访问时执行额外的动作。例如引用计数和线程安全检查。 延迟初始化我们先创建一个LazyProperty类，用作一个装饰器。当它修饰某个特性时，LazyProperty 惰性地（首次使用时）加载特性，而不是立即进行。 1234567891011121314151617181920212223242526272829303132333435363738class LazyProperty: def __init__(self, method): self.method = method self.method_name = method.__name__ def __get__(self, instance, owner): if not instance: return None value = self.method(instance) setattr(owner, self.method_name, value) return valueclass Test: def __init__(self): self.x = 'foo' self.y = 'bar' self._resource = None @LazyProperty def resource(self): # 构造函数里没有初始化，第一次访问才会被调用 print('initializing self._resource which is: &#123;&#125;'.format(self._resource)) self._resource = tuple(range(5)) # 模拟一次耗时计算 return self._resourcedef main(): t = Test() print(t.x) print(t.y) # 访问LazyProperty, resource里的print语句只执行一次，实现了延迟加载和一次执行 print(t.resource) print(t.resource)if __name__ == '__main__': main() LazyProperty类实际上是一个描述符。 描述符（descriptor）是Python中重写类属性访问方法（__get__()、 __set__()和__delete__()）的默认行为要使用的一种推荐机制。Test类演示了我们可以如何使用LazyProperty类。其中有三个属性， x、 y 和 _resource。我们想懒加载 _resource 变量，因此将其初始化为None。 在OOP中有两种基本的、不同类型的懒加载，如下所示： 在实例级：这意味着会一个对象的特性进行懒初始化，但该特性有一个对象作用域。同一个类的每个实例（对象）都有自己的（不同的）特性副本。 在类级或模块级：在这种情况下，我们不希望每个实例都有一个不同的特性副本，而是所有实例共享同一个特性，而特性是懒初始化的。 保护代理这里实现一个简单的保护代理来查看和添加用户，该服务提供以下两个选项： 查看用户列表：这一操作不要求特殊权限。 添加新用户：这一操作要求客户端提供一个特殊的密码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class SensitiveInfo: def __init__(self): self.users = ['nick', 'tom', 'ben', 'mike'] def read(self): result = 'There are &#123;&#125; users: &#123;&#125;' print(result.format(len(self.users), ' '.join(self.users))) def add(self, user): self.users.append(user) print('Added user &#123;&#125;'.format(user))class Info: def __init__(self): self.protected = SensitiveInfo() self.secret = '0xdeadbeef' def read(self): self.protected.read() def add(self, user): sec = input('what is the secret? ') self.protected.add(user) if sec == self.secret else print("That's wrong!")def main(): info = Info() while True: print('1. read list |==| 2. add user |==| 3. quit') key = input('choose option: ') if key == '1': info.read() elif key == '2': name = input('choose username: ') info.add(name) elif key == '3': exit() else: print('unknown option: &#123;&#125;'.format(key))if __name__ == '__main__': main() 该示例有几个重大的安全缺陷： 没有什么能阻止客户端代码通过直接创建一个 SensitiveInfo 实例来绕过应用的安全设置，疑使用 abc 模块来禁止直接实例化 SensitiveInfo。 密钥直接写死在代码里，应该用安全性较高密钥写到配置或者环境变量里。 这里使用抽象基类来修复第一个问题，只需要修改类代码而不用修改 main() 函数里面的使用代码：123456789101112131415161718192021222324252627282930from abc import ABCMeta, abstractmethodclass SensitiveInfo(metaclass=ABCMeta): def __init__(self): self.users = ['nick', 'tom', 'ben', 'mike'] @abstractmethod def read(self): pass @abstractmethod def add(self, user): passclass Info(SensitiveInfo): '''protection proxy to SensitiveInfo''' def __init__(self): # self.protected = SensitiveInfo() super().__init__() self.secret = '0xdeadbeef' # 为了方便示例这里直接写死在代码里 def read(self): print('There are &#123;&#125; users: &#123;&#125;'.format(len(self.users), ' '.join(self.users))) def add(self, user): """ 给add操作加上密钥验证，保护add操作""" sec = input('what is the secret? ') self.users.append(user) if sec == self.secret else print("That's wrong!")]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之MVC模式]]></title>
    <url>%2F2018%2F10%2F22%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BMVC%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[MVC是一个非常重要的设计模式，用于将应用组织成三个部分：模型、视图和控制器。同时，MVC也是一种架构模式，比如流行的 Django 框架就是 MVC(MTV) 模式。 每个部分都有明确的职责。模型负责访问数据，管理应用的状态。视图是模型的外在表现。视图并非必须是图形化的；文本输出也是一种好视图。控制器是模型与视图之间的连接。 MVC的恰当使用能确保最终产出的应用易于维护、易于扩展。 示例如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253quotes = ('A man is not complete until he is married. Then he is finished.', 'As I said before, I never repeat myself.', 'Behind a successful man is an exhausted woman.', 'Black holes really suck...', 'Facts are stubborn things.')class QuoteModel: def get_quote(self, n): try: value = quotes[n] except IndexError as e: value = 'Not found!' return valueclass QuoteTerminalView: def show(self, quote): print('And the quote is: "&#123;&#125;"'.format(quote)) def error(self, msg): print('Error: &#123;&#125;'.format(msg)) def select_quote(self): return input('Which quote number would you like to see? ')class QuoteTerminalController: def __init__(self): self.model = QuoteModel() self.view = QuoteTerminalView() def run(self): valid_input = False while not valid_input: n = self.view.select_quote() try: n = int(n) except ValueError as e: self.view.error("Incorrect index '&#123;&#125;'".format(n)) else: valid_input = True quote = self.model.get_quote(n) self.view.show(quote)def main(): controller = QuoteTerminalController() while True: controller.run()if __name__ == '__main__': main()]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之享元模式]]></title>
    <url>%2F2018%2F10%2F19%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[OOP中容易出现对象创建带来的性能和内存占用问题，当我们想要优化内存使用提高应用性能之时，可以使用享元模式。而想要使享元模式有效，需要满足以下几个条件： 需要使用大量对象（Python 中可以使用__slots__节省内存使用） 对象太多难以存储或解析大量对象 对象识别不是特别重要，共享对象中对象比较会失败 通常情况下，会使用对象池技术来实现共享对象，比如数据库中经常使用连接池来减少开销，预先建立一些连接池，每次取一个连接和数据库交互。 一般来说，在应用需要创建大量的计算代价大但共享许多属性的对象时，可以使用享元。重点在于将不可变（可共享）的属性与可变的属性区分开。这里以一个树渲染器，支持三种不同的树家族为例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import randomfrom enum import EnumTreeType = Enum('TreeType', ('apple_tree', 'cherry_tree', 'peach_tree'))class Tree: pool = dict() def __new__(cls, tree_type): obj = cls.pool.get(tree_type, None) if not obj: obj = object.__new__(cls) cls.pool[tree_type] = obj obj.tree_type = tree_type return obj def render(self, age, x, y): print(f'render a tree of type &#123;self.tree_type&#125;' f' and age &#123;age&#125; at (&#123;x&#125;, &#123;y&#125;)')def main(): rnd = random.Random() age_min, age_max = 1, 30 # 单位为年 min_point, max_point = 0, 100 tree_counter = 0 for _ in range(10): t1 = Tree(TreeType.apple_tree) t1.render(rnd.randint(age_min, age_max), rnd.randint(min_point, max_point), rnd.randint(min_point, max_point)) tree_counter += 1 for _ in range(3): t2 = Tree(TreeType.cherry_tree) t2.render(rnd.randint(age_min, age_max), rnd.randint(min_point, max_point), rnd.randint(min_point, max_point)) tree_counter += 1 for _ in range(5): t3 = Tree(TreeType.peach_tree) t3.render(rnd.randint(age_min, age_max), rnd.randint(min_point, max_point), rnd.randint(min_point, max_point)) tree_counter += 1 print('trees rendered: &#123;&#125;'.format(tree_counter)) print('trees actually created: &#123;&#125;'.format(len(Tree.pool))) t4 = Tree(TreeType.cherry_tree) t5 = Tree(TreeType.cherry_tree) t6 = Tree(TreeType.apple_tree) print('&#123;&#125; == &#123;&#125;? &#123;&#125;'.format(id(t4), id(t5), id(t4) == id(t5))) print('&#123;&#125; == &#123;&#125;? &#123;&#125;'.format(id(t5), id(t6), id(t5) == id(t6)))if __name__ == '__main__': main()]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之外观模式]]></title>
    <url>%2F2018%2F10%2F18%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[一个系统会随着演进而变得非常复杂，最终形成大量的（并且有时是令人迷惑的）类和交互，这种情况并不少见。 但许多情况下，我们并不想把这种复杂性暴露给客户端。而外观设计模式有助于隐藏系统的内部复杂性，并通过一个简化的接口向客户端暴露必要的部分。本质上，外观模式是在已有的系统上实现的一个抽象层。 这里以一个简单的操作系统示例来说明外观模式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293from enum import Enumfrom abc import ABCMeta, abstractmethodState = Enum('State', ['new', 'running', 'sleeping', 'restart', 'zombie'])class Server(metaclass=ABCMeta): @abstractmethod def __init__(self): pass def __str__(self): return self.name @abstractmethod def boot(self): pass @abstractmethod def kill(self, restart=True): passclass FileServer(Server): def __init__(self): '''初始化文件服务进程要求的操作''' self.name = 'FileServer' self.state = State.new def boot(self): print('booting the &#123;&#125;'.format(self)) '''启动文件服务进程要求的操作''' self.state = State.running.value def kill(self, restart=True): print('Killing &#123;&#125;'.format(self)) '''终止文件服务进程要求的操作''' self.state = State.restart if restart else State.zombie def create_file(self, user, name, permissions): '''检查访问权限的有效性和用户权限等''' print(f"trying to create the file '&#123;name&#125;'" f" for user '&#123;user&#125;' with permissions &#123;permissions&#125;")class ProcessServer(Server): def __init__(self): '''初始化进程服务进程要求的操作''' self.name = 'ProcessServer' self.state = State.new def boot(self): print('booting the &#123;&#125;'.format(self)) '''启动进程服务进程要求的操作''' self.state = State.running def kill(self, restart=True): print('Killing &#123;&#125;'.format(self)) '''终止进程服务进程要求的操作''' self.state = State.restart if restart else State.zombie def create_process(self, user, name): '''检查用户权限和生成PID等''' print(f"trying to create the process '&#123;name&#125;' for user '&#123;user&#125;'")class OperatingSystem: def __init__(self): self.fs = FileServer() self.ps = ProcessServer() def start(self): [item.boot() for item in (self.fs, self.ps)] def create_file(self, user, name, permissions): self.fs.create_file(user, name, permissions) def create_process(self, user, name): self.ps.create_process(user, name)def main(): os = OperatingSystem() os.start() os.create_file('foo', 'hello', '-rw-r-r') os.create_process('bar', 'ls /tmp')if __name__ == '__main__': main()]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之装饰器模式]]></title>
    <url>%2F2018%2F10%2F17%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[当我们想对一个已有的对象添加额外的功能时，可以使用如下方法： 如果合理，可以直接将功能添加到对象所属的类（例如，添加一个新的方法）。 使用组合 使用继承 与继承相比，通常应该优先选择组合，因为继承使得代码更难复用，继承关系是静态的，并且应用于整个类以及这个类的所有实例。 设计模式为我们提供了第四种可选的方法，以支持动态的扩展一个对象的功能，这种方法就是装饰器。 装饰器有很多用途，比如数据校验，事务处理，缓存，日志等。 这里以装饰器实现斐波那契数列缓存为例：1234567891011121314151617181920import functoolsdef memoize(fn): known = &#123;&#125; @functools.wraps(fn) def decorator(args): if args not in known: known[args] = fn(args) return known[args] return decorator@memoizedef fibonacci(n): '''返回斐波那契数列的第n个数''' assert (n &gt;= 0), 'n must be &gt;= 0' return n if n in (0, 1) else fibonacci(n - 1) + fibonacci(n - 2)]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之适配器模式]]></title>
    <url>%2F2018%2F10%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[适配器模式（Adapter pattern）是一种结构型设计模式，帮助我们实现两个不兼容接口之间的兼容。不兼容接口的含义：如果我们希望把一个老组件用于一个新系统中，或者把一个新组件用于一个老系统中，不对代码进行任何修改两者就能够通信的情况很少见。但又并非总是能修改代码，或因为我们无法访问这些代码（例如，组件以外部库的方式提供），或因为修改代码本身就不切实际。在这些情况下，我们可以编写一个额外的代码层，该代码层包含让两个接口之间能够通信需要进行的所有修改。这个代码层就叫适配器。 现实中最好的例子就是手机充电口，不同型号安卓手机都可以用同样的充电线充电。 好处适配器模式的好处：1）不要求访问他方接口的源代码。2）不违反开放/封闭原则。 实现使用 Python 实现适配器模式有多种方式，可以通过继承的方式来实现适配器，也可以通过class的__dict__来实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# external.pyclass Synthesizer: def __init__(self, name): self.name = name def __str__(self): return 'the &#123;&#125; synthesizer'.format(self.name) def play(self): return 'is playing an electronic song'class Human: def __init__(self, name): self.name = name def __str__(self): return '&#123;&#125; the human'.format(self.name) def speak(self): return 'say hello'# adapter.pyfrom external import Synthesizer, Humanclass Computer: def __init__(self, name): self.name = name def __str__(self): return 'the &#123;&#125; computer'.format(self.name) def execute(self): return 'executes a program.'class Adapter: def __init__(self, obj, adapted_methods): self.obj = obj self.__dict__.update(adapted_methods) def __str__(self): return str(self.obj)def main(): objects = [Computer('Asus')] synth = Synthesizer('moog') objects.append(Adapter(synth, dict(execute=synth.play))) human = Human('Bob') objects.append(Adapter(human, dict(execute=human.speak))) for i in objects: print('&#123;&#125; &#123;&#125;'.format(str(i), i.execute()))if __name__ == '__main__': main()]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在字典中将键映射到多个值上]]></title>
    <url>%2F2018%2F10%2F15%2F%E5%9C%A8%E5%AD%97%E5%85%B8%E4%B8%AD%E5%B0%86%E9%94%AE%E6%98%A0%E5%B0%84%E5%88%B0%E5%A4%9A%E4%B8%AA%E5%80%BC%E4%B8%8A%2F</url>
    <content type="text"><![CDATA[问题我们想要将一个列表，里面是(key, value)这样的键值对元组，转换成一个key相同的value的字典，如下所示：1234567data = [('a', 1), ('a', 2), ('a', 3), ('b', 4), ('b', 5)]# convert tod = &#123; 'a': [1, 2, 3], 'b': [4, 5]&#125; 解决通常来说，要进行这样的转换是很容易的，但很多时候会写出下面不够 Pythonic 的代码：12345result = &#123;&#125;for (key, value) in data: if key not in result: result[key] = [] result[key].append(value) 这时我们可以使用 collections 模块中的 defaultdict 类。defaultdict 的一个特点就是它会自动初始化第一个值，这样只需关注添加元素即可。例如： 12345from collections import defaultdictresult = defaultdict(lits)for (key, value) in data: result[key].append(value) 关于 defaultdict ， 需要注意的一个地方是，它会自动创建字典表项以待稍后的访问（即使这些表项当前在字典中还没找到）。如果不想要这个功能，可以在普通的字典上调用 setdefault() 方法来取代。例如：123result = dict()for (key, value) in data: result.setdefault(key, []).append(value) 参考： Python Cookbook]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>小技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之原型模式]]></title>
    <url>%2F2018%2F10%2F15%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[原型模式（The Prototype Pattern）用于创建对象的完全副本，有点类似与现实生活中的有丝分裂，在 Python 中可以使用内置的copy模块实现。 拷贝分为深拷贝和浅拷贝： 深拷贝会递归复制并创建新的对象 浅拷贝会利用引用指向同一个对象 深拷贝的优点是对象之间互不影响，但是会耗费资源，创建比较耗时；如果不会修改对象可以使用浅拷贝，更加节省资源和创建时间。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import copyfrom collections import OrderedDictclass Book: def __init__(self, name, authors, price, **rest): self.name = name self.authors = authors self.price = price self.__dict__.update(rest) def __str__(self): mylist = [] ordered = OrderedDict(sorted(self.__dict__.items())) for i in ordered.keys(): mylist.append('&#123;&#125;: &#123;&#125;'.format(i, ordered[i])) if i == 'price': mylist.append('$') mylist.append('\n') return ''.join(mylist)class Prototype: def __init__(self): self.objects = dict() def register(self, identifier, obj): self.objects[identifier] = obj def unregister(self, identifier): del self.objects[identifier] def clone(self, identifier, **attr): """ 实现对象拷贝 """ found = self.objects.get(identifier) if not found: raise ValueError( 'Incorrect object identifier: &#123;&#125;'.format(identifier)) obj = copy.deepcopy(found) obj.__dict__.update(attr) # 实现拷贝时自定义更新 return objdef main(): b1 = Book('The C Programming Language', ('Brian W. Kernighan', 'Dennis M.Ritchie'), price=118, publisher='Prentice Hall', length=228, publication_date='1978-02-22', tags=('C', 'programming', 'algorithms', 'data structures')) prototype = Prototype() cid = 'k&amp;r-first' prototype.register(cid, b1) b2 = prototype.clone(cid, name='The C Programming Language(ANSI)', price=48.99, length=274, publication_date='1988-04-01', edition=2) for i in (b1, b2): print(i) print("ID b1 : &#123;&#125; != ID b2 : &#123;&#125;".format(id(b1), id(b2)))if __name__ == '__main__': main()]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之构造模式]]></title>
    <url>%2F2018%2F10%2F14%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E6%9E%84%E9%80%A0%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[当出现以下几种情况时，可以考虑使用构造模式： 当想要创建一个复杂对象(对象由多个部分构成，且对象的创建要经过多个不同的步骤，这些步骤也许还遵从特定的顺序) 要求一个对象能有不同的表现，并希望将对象的构造与表现解耦 想要在某个时间点创建对象，但在稍后的时间点再访问 可以这么理解，你要买电脑，工厂模式直接返回一个你需要型号的电脑，但是构造模式允许你自定义电脑各种配置类型，组装完成后给你。这个过程你可以传入builder从而自定义创建的方式。 方式一1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class Computer: def __init__(self, serial_number): self.serial_number = serial_number self.memory = None self.hdd = None self.gpu = None def __str__(self): info = ('Memory: &#123;&#125;GB'.format(self.memory), 'Hard Disk: &#123;&#125;GB'.format(self.hdd), 'Graphics Card: &#123;&#125;'.format(self.gpu)) return '\n'.join(info)class ComputerBuilder: def __init__(self): self.computer = Computer('AG23385193') def configure_memory(self, memory): self.computer.memory = memory def configure_hdd(self, amount): self.computer.hdd = amount def configure_gpu(self, gpu_model): self.computer.gpu = gpu_modelclass HardwareEngineer: def __init__(self): self.builder = None def construct_computer(self, memory, hdd, gpu): self.builder = ComputerBuilder() [step for step in (self.builder.configure_memory(memory), self.builder.configure_hdd(hdd), self.builder.configure_gpu(gpu))] @property def computer(self): return self.builder.computerdef main(): # 使用buidler，可以创建多个builder类实现不同的组装方式 engineer = HardwareEngineer() engineer.construct_computer(hdd=500, memory=8, gpu='GeForce GTX 650 Ti') computer = engineer.computer print(computer)if __name__ == '__main__': main() 方式二这种方式以前在 Android 开发使用 Retrofit 库时使用过，这是一种链式调用。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Computer: def __init__(self, builder): self.serial_number = builder.serial_number self.memory = builder.memory self.hdd = builder.hdd self.gpu = builder.gpu def __str__(self): info = ('Memory: &#123;&#125;GB'.format(self.memory), 'Hard Disk: &#123;&#125;GB'.format(self.hdd), 'Graphics Card: &#123;&#125;'.format(self.gpu)) return '\n'.join(info) class ComputerBuilder: def __init__(self): self.serial_number = None self.memory = None self.hdd = None self.gpu = None def configure_serial_number(self, serial_number): self.serial_number = serial_number return self def configure_memory(self, memory): self.memory = memory return self def configure_hdd(self, amount): self.hdd = amount return self def configure_gpu(self, gpu_model): self.gpu = gpu_model return self def build(self): return Computer(self)def main(): computer = (Computer.ComputerBuilder() .configure_serial_number('AG23385193') .configure_memory(8) .configure_hdd(500) .configure_gpu('GeForce GTX 650 Ti') .build()) print(computer)if __name__ == '__main__': main()]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python工厂模式]]></title>
    <url>%2F2018%2F10%2F12%2FPython%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[工厂模式主要是为了解决对象创建问题：客户端可以请求一个对象，而不需要知道这个对象来自哪里，换句话说，客户端在请求一个对象时，不需要知道该对象是被哪一个类创建的。这样做的好处是可以方便的解耦对象的使用和创建，工厂模式有两种实现方式：工厂方法和抽象工厂。 1.工厂方法执行单个函数，通过传递的参数来确定需要的对象信息。1234567891011121314151617181920212223242526272829303132333435363738394041import jsonimport xml.etree.ElementTree as etreeclass JSONConnector: def __init__(self, filepath): self.data = dict() with open(filepath, mode='r', encoding='utf-8') as f: self.data = json.load(f) @property def parsed_data(self): return self.dataclass XMLConnector: def __init__(self, filepath): self.tree = etree.parse(filepath) @property def parsed_data(self): return self.treedef connection_factory(filepath): if filepath.endswith('json'): connector = JSONConnector elif filepath.endswith('xml'): connector = XMLConnector else: raise ValueError('Cannot connect to &#123;&#125;'.format(filepath)) return connector(filepath)def connect_to(filepath): factory = None try: factory = connection_factory(filepath) except ValueError as e: print(e) return factory 2.抽象工厂抽象工厂设计模式是抽象方法的一种泛化。概括来说，一个抽象工厂是（逻辑上的）一组工厂方法，其中的每个工厂方法负责产生不同种类的对象。 工厂方法适合对象种类比较少的情况，当有多种不同类型的对象需要创建时，就需要使用抽象模式。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980class Frog: def __init__(self, name): self.name = name def __str__(self): return self.name def interact_with(self, obstacle): print('&#123;&#125; the Frog encounters &#123;&#125; and &#123;&#125;!'.format( self, obstacle, obstacle.action()))class Bug: def __str__(self): return 'a bug' def action(self): return 'eats it'class FrogWorld: def __init__(self, name): print(self) self.player_name = name def __str__(self): return '\n\n\t----Frog World -----' def make_characters(self): return Frog(self.player_name) def make_obstacle(self): return Bug()class Wizard: def __init__(self, name): self.name = name def __str__(self): return self.name def interact_with(self, obstacle): print('&#123;&#125; the Wizard battles against &#123;&#125; and &#123;&#125;!'.format( self, obstacle, obstacle.action()))class Ork: def __str__(self): return 'an evil ork' def action(self): return 'kill it'class WizardWorld: def __init__(self, name): print(self) self.player_name = name def __str__(self): return '\n\n\t----Wizard World -----' def make_characters(self): return Wizard(self.player_name) def make_obstacle(self): return Ork()class GameEnvironment: """ 抽象工厂，根据不同的玩家类型创建不同的角色和障碍 (游戏环境) 这里可以根据年龄判断，成年人返回『巫师』游戏，小孩返回『青蛙过河』游戏""" def __init__(self, factory): self.hero = factory.make_characters self.obstacle = factory.make_obstacle() def play(self): self.hero.interact_with(self.obstacle)]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python单例模式]]></title>
    <url>%2F2018%2F10%2F11%2FPython%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Python单例模式 Design ptterns are discoverd, not invented.- Alex Martelli 1.使用模块因为在 Python 中导入模块时，第一次导入会生成.pyc文件，第二次导入时就直接加载.pyc文件了，而不会再次执行模块中的代码，所以 Python 中使用模块是最天然的单例模式。123456# module.pyclass Singleton: pass instance = Singleton() 使用方式：1234import module# or from module import instancemodule.instance 2.__new__Python 中真正的构造方法是__new__，而不是__init__，这时我们就可以在__new__中做文章：1234567class Singleton: _instance = &#123;&#125; def __new__(cls, *args, **kwargs): if cls not in cls._instance: cls._instance[cls] = super(Singleton, cls).__new__(cls) return cls._instance[cls] 这种方式在并发的情况下可能会发生意外，为了解决这个问题，引入一个带锁的版本: 12345678910111213141516171819import threadingclass Singleton: _instance = &#123;&#125; locker = threading.Lock() def __new__(cls, *args, **kwargs): if cls in cls._instance: return cls._instance[cls] cls.locker.acquire() try: if cls in cls._instance: return cls._instance[cls] cls._instance[cls] = super(Singleton, cls).__new__(cls) finally: cls.locker.release() return cls._instance[cls] 利用经典的双检查锁机制，确保了在并发环境下 Singleton 的正确实现。但这个方案并不完美，至少还有以下两个问题: 如果 Singleton 的子类重写了__new__()方法，会覆盖或者干扰 Singleton 类中__new__()的执行，虽然这种情况出现的概率极小，但也不可忽视。 如果子类有__init__()方法，那么每次示例化该 Singleton 的时候，__init__()都会被调用到，这个显然是不应该的，__init__()只应该在创建实例的时候被调用一次。 这两个问题当然可以解决，比如第一个问题可以通过文档告知该类的使用者，如果要重载 Singleton 的__new__()方法，请务必记得调用父类的__new__()方法；而第二个问题也可以通过替换掉__init__()方法来确保它只调用一次。 但是，为了实现一个单例，做大量的水面之下的工作让人感觉相当不 Pythonic，这也引起了 Python 社区的反思，有人开始重新审视 Python 的语法元素，发现模块其实是天然的单例实现方式（即第一种实现方式)，这是因为: 所有的变量都会绑定到模块 模块只初始化一次 import 机制是线程安全的（保证了在并发状态下模块也只有一个实例） 3.共享属性(Borg模式)Borg 模式与单例模式其实是不同的，单例模式关注的是对象一致，然而这可能未必是我们使用单例模式的原因，有可能我们关注的是实例的状态一致，这种情况下就可以使用 Borg 模式。 12345class Borg: _state = &#123;&#125; def __init__(self): self.__dict__ = self._state 4.使用元类1234567891011121314151617class Singleton(type): _instances = &#123;&#125; def __call__(cls, *args, **kwargs): if cls not in cls._instances: cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs) return cls._instances[cls] # python2class YourClass(object): __metaclass__ = Singleton # python3class YourClass(metaclass=Singleton): pass]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[0到1，Celery从入门到出家]]></title>
    <url>%2F2018%2F09%2F28%2F0%E5%88%B01%EF%BC%8CCelery%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%87%BA%E5%AE%B6%2F</url>
    <content type="text"><![CDATA[本文转载自公众号「Python之禅」，原文链接：https://mp.weixin.qq.com/s/w63Ut5zZjlOypvrhO7YWIA 在一个应用服务中，对于时效性要求没那么高的业务场景，我们没必要等到所有任务执行完才返回结果，例如用户注册场景中，保存了用户账号密码之后，就可以立即返回，后续的账号激活邮件，可以用一种异步的形式去处理，这种异步操作可以用队列服务来实现。否则，如果等到邮件发送成功可能几秒过去了。 Celery是什么？Celery（中文是芹菜的意思）是Python语言实现的分布式队列服务，除了支持即时任务，还支持定时任务，Celery 有5个核心角色。 Task任务(Task)就是你要做的事情，例如一个注册流程里面有很多任务，给用户发验证邮件就是一个任务，这种耗时的任务就可以交给Celery去处理，还有一种任务是定时任务，比如每天定时统计网站的注册人数，这个也可以交给Celery周期性的处理。 BrokerBroker 的中文意思是经纪人，指为市场上买卖双方提供中介服务的人。在Celery中这个角色相当于数据结构中的队列，介于生产者和消费者之间经纪人。例如一个Web系统中，生产者是主程序，它生产任务，将任务发送给 Broker，消费者是 Worker，是专门用于执行任务的后台服务。Celery本身不提供队列服务，一般用Redis或者RabbitMQ来实现队列服务。 WorkerWorker 就是那个一直在后台执行任务的人，也成为任务的消费者，它会实时地监控队列中有没有任务，如果有就立即取出来执行。 BeatBeat 是一个定时任务调度器，它会根据配置定时将任务发送给 Broker，等待 Worker 来消费。 BackendBackend 用于保存任务的执行结果，每个任务都有返回值，比如发送邮件的服务会告诉我们有没有发送成功，这个结果就是存在Backend中，当然我们并不总是要关心任务的执行结果。 记住这5个角色后面理解Celery就轻松了。 快速入门接触任何新东西，没有什么比实际动手学得更快了。假设我们选择Redis作为broker，你需要安装redis并且已经启动了redis服务（这个步骤请自行借用搜索引擎解决） 1pip install -U "celery[redis]" 1.创建Celery实例1234# tasks.pyfrom celery import Celeryapp = Celery('tasks', broker='redis://localhost:6379/0') 2.创建任务假设这个发送邮件的任务需要5秒钟才能执行完1234567# task.py@app.taskdef send_mail(mail): print("send mail to ", email) import time time.sleep(5) return "success" 在没有Celery的情况下，程序顺序执行，每个步骤都需要等上一步执行完成。 插入记录到数据库 发邮件 注册成功 我们可以把2放在一个任务中交给celery去执行，这样我们就不需要等待发邮件完成，你只需要安排celery去处理帮我去完成就好了。代码就变成了 插入记录到数据库 Celery 帮我发邮件 注册成功 第二步是非常快的，它只需要把任务放进队列里面去，并不会等任务真正执行完。这跟生活是完全贴切的，例如我们很多事情都不是自己亲历其为去做，而是将一个不太重要或即时性没那么高的事情转交给别人处理。 3.启动Worker启动Worker，监听 Broker 中是否有任务，命令：celery worker，你可能需要指定参数1celery -A tasks worker --loglevel=info -A： 指定 celery 实例所在哪个模块中，例子中，celery实例在tasks.py文件中，启动成功后，能看到信息 函数用app.task 装饰器修饰之后，就会成为Celery中的一个Task。 4.调用任务在主程序中调用任务，调任务发送给 Broker，而不是真正执行该任务 1234567891011121314# user.pyfrom tasks import send_maildef register(): import time start = time.time() print("1. 插入记录到数据库") print("2. celery 帮我发邮件") send_mail.delay("xx@gmail.com") print("3. 告诉用户注册成功") print("耗时：%s 秒 " % (time.time() - start))if __name__ == '__main__': register() 在主程序中，调用函数的.delay方法 目录结构： ── celery_test ├── tasks.py └── user.py 运行 python user.py， 启动应用程序12341. 插入记录到数据库2. celery 帮我发邮件3. 告诉用户注册成功耗时：0.22688984870910645 秒 程序花了不到0.23秒就执行完成，如果按照正常的同步逻辑去执行，至少需要5秒钟，因为发邮件的任务就花了5秒。在worker服务窗口看日志信息 注意 celery worker 启动时，如果是 root 用户，需要设置环境变量： 1export C_FORCE_ROOT='true' Celery4.x 开始不再支持Windows平台，如果需要在Windows开发，请使用3.x的版本。 使用 RabbitMQ 或 Redis 作为 Broker，生产环境永远不要使用关系数据库 不要使用复杂对象作为任务函数的参数 123456789101112# Good@app.taskdef my_task(user_id): user = User.objects.get(id=user_id) print(user.name) # ... # Bad@app.taskdef my_task(user): print(user.name) # ... 小结学习Celery，首先需要知道它的应用场景，然后是Celery中的常见角色，最后按照步骤感受一下Celery是如何跑起来的。 参考链接： http://funhacks.net/2016/12/13/celery/ https://celery.readthedocs.io/en/latest/userguide/tasks.html#tips-and-best-practices http://celerytaskschecklist.com/]]></content>
      <categories>
        <category>Celery</category>
      </categories>
      <tags>
        <tag>Celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL中 only_full_group_by 问题]]></title>
    <url>%2F2018%2F08%2F08%2FMySQL%E4%B8%AD-only-full-group-by-%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[最近在试用 MySQL 数据库做查询时，遇到了这么个问题，当我使用 GROUP_BY对要查询的数据进行分组的时候，抛出了一个InternalError的错误，当时我：？？？ 1055, “Expression #1 of SELECT list is not in GROUP BY clause and contains nonaggregated column ‘xxx’ which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by” 意思就是说，你写的 SQL 语句在sql_mode=only_full_group_by模式下是不兼容的，非聚类列‘xxx’没有出现在 GROUP_BY 子句中。 用Google搜了下，在官方文档上发现了这个问题的详细说明，具体请看：MySQL :: MySQL 5.7 Reference Manual :: 12.19.3 MySQL Handling of GROUP BY MySQL 5.7.5 and up implements detection of functional dependence. If the ONLY_FULL_GROUP_BY SQL mode is enabled (which it is by default), MySQL rejects queries for which the select list, HAVING condition, or ORDER BY list refer to nonaggregated columns that are neither named in the GROUP BY clause nor are functionally dependent on them. (Before 5.7.5, MySQL does not detect functional dependency and ONLY_FULL_GROUP_BY is not enabled by default. For a description of pre-5.7.5 behavior, see the MySQL 5.6 Reference Manual.) 大致就是在 MySQL 5.7.5 版本之前，遵循 SQL92 标准的 ONLY_FULL_GROUP_BY 模式在默认情况下是关闭的，MySQL 并未强行按照 SQL92 标准编写查询语句，而在 5.7.5 之后的版本中，ONLY_FULL_GROUP_BY 的含义改变了，由于遵循了 SQL99 标准，现在将实现更为复杂的功能。也就是说，有时候写的代码变少了，也同样可以实现查询功能。 解决方法1.关闭 ONLY_FULL_GROUP_BY 模式关闭 ONLY_FULL_GROUP_BY 方法这个方法最简单粗暴，但也同样有着问题，在文档中给出了相关的说明，当 ONLY_FULL_GROUP_BY 模式被禁用时，查询出来的每个组中值是随机选取的，这就导致结果可能不符合你的预期。 2.使用 ANY_VALUE1SELECT name, address, MAX(age) FROM t GROUP BY name; 这么一条查询语句在不禁用 ONLY_FULL_GROUP_BY 模式的情况下，也会出现最开始的错误。1SELECT name, ANY_VALUE(address), MAX(age) FROM t GROUP BY name; 而使用 ANY_VALUE 函数后，则不会，ANY_VALUE 同样是随机选取值。 3.更好的SQL查询语句这个还在学习中，以后再做补充]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「Python3学习笔记」读书笔记—集合]]></title>
    <url>%2F2018%2F06%2F29%2F%E3%80%8CPython3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%8D%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E2%80%94%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[集合存储的是非重复对象，所谓的非重复对象是指：除了不是同一对象外，值也不能相同。12# Python集合判重公式(a is b) OR (hash(a) == hash(b) AND a == b) 如果不是同一对象，那么先判断哈希值，然后比较内容。因为受限于哈希算法，不同内容可能返回相同的哈希值（哈希碰撞），那么就有必要继续比较内容是否相同。 那么为什么要先比较哈希值，而不直接比较内容呢？首先，与大多数内容（例如字符串）相比，整数哈希值比较的性能高得多；其次，哈希值不同，内容肯定不同，这时就没必要再继续比较内容了。 按操作方式来分的话，集合可分为可变（set）和不可变（frozenset）两个版本，内部实现完全相同。集合使用数组实现的哈希表来存储元素对象的引用，这也意味着集合中的元素必须为可哈希类型。 查找元素对象时，先通过算法定位数组索引，继而比较哈希值和内容。 集合对象自带一个长度为 8 的小数组（small table)，这对多数简单集合运算有益，可避免额外的内存分配。只有超出容量限制时，才分配更大的数组内存（entry table)。集合使用的频率没有列表和字典高，内部没有采用缓存服用策略，其实现方式决定了无序存储，标准库也没有提供有序实现。 创建创建一个集合对象可以和字典一样使用大括号的语法，但初始化数据用非键值对；也可以调用类型构建方法，或使用推导式。集合允许在不同的版本进行转换。1234&gt;&gt;&gt; s = &#123;1&#125;&gt;&gt;&gt; f = frozenset(s)&gt;&gt;&gt; set(f)&#123;1&#125; 操作集合支持大小、相等运算符。1234&gt;&gt;&gt; &#123;1, 2&#125; &gt; &#123;2, 1&#125;False&gt;&gt;&gt; &#123;1, 2&#125; == &#123;2, 1&#125;True 但子集判断不能使用 in、not in 语句，因为其只能用来检查是否包含某个元素。123456&gt;&gt;&gt; &#123;1, 2&#125; &lt;= &#123;1, 2, 3&#125; # 子集：issubsetTrue&gt;&gt;&gt; &#123;1, 2, 3&#125; &gt;= &#123;1, 2&#125; # 超集：issupersetTrue&gt;&gt;&gt; &#123;1, 2&#125; in &#123;1, 2, 3&#125; # 判断是否包含 &#123;1, 2&#125; 单一元素False 集合是初等数学中的概念，其重点自然是并差集运算，合理使用这些操作，可简化算法筛选逻辑，使其具备更好的可读性。 交集（&amp;）：同时属于 A、B 两个集合的元素并集（|）：A、B 的所有元素差集（-）：仅属于 A、不属于 B 的元素对称差集（^）：仅属于 A，加上仅属于 B 的元素，相当于“并集-交集” 集合支持删除操作，但 remove 可能会引发异常，可改用 discard。12345678&gt;&gt;&gt; x = &#123;1, 2&#125;&gt;&gt;&gt; x.remove(2)&gt;&gt;&gt; x.remove(2)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;KeyError: 2&gt;&gt;&gt; x.discard(2) 自定义类型自定义类型虽然是可哈希类型，但默认实现并不足以完成集合的去重操作。1234class User: def __init__(self, uid, name): self.uid = uid self.name = name 1234567891011&gt;&gt;&gt; import collections&gt;&gt;&gt; issubclass(User, collections.Hashable)True&gt;&gt;&gt; u1 = User(1, &quot;user1&quot;)&gt;&gt;&gt; u2 = User(1, &quot;user1&quot;)&gt;&gt;&gt; s = set()&gt;&gt;&gt; s.add(u1)&gt;&gt;&gt; s.add(u2)&gt;&gt;&gt; s&#123;&lt;__main__.User object at 0x10bc1df98&gt;, &lt;__main__.User object at 0x10bc29048&gt;&#125; 其根本原因是默认实现的__hash__方法返回随机值，而__eq__仅比较自身，为符合逻辑需要，须重载这两个方法。12345678910class User: def __init__(self, uid, name): self.uid = uid self.name = name def __hash__(self): # 针对 uid 去重，忽略其他字段 return hash(self.uid) def __eq__(self, other): return self.uid == other.uid 1234567891011&gt;&gt;&gt; u1 = User(1, &quot;user1&quot;)&gt;&gt;&gt; u2 = User(1, &quot;user1&quot;)&gt;&gt;&gt; s = set()&gt;&gt;&gt; s.add(u1)&gt;&gt;&gt; s.add(u2)&gt;&gt;&gt; s&#123;&lt;__main__.User object at 0x10bc1df98&gt;&#125;&gt;&gt;&gt; u1 in sTrue&gt;&gt;&gt; u2 in s # 仅检查 uid 字段True]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「Python3学习笔记」读书笔记—字典]]></title>
    <url>%2F2018%2F06%2F25%2F%E3%80%8CPython3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%8D%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E2%80%94%E5%AD%97%E5%85%B8%2F</url>
    <content type="text"><![CDATA[字典是内置类型中唯一的映射（Mapping）结构，基于哈希表存储键值对数据。 值可以是任意类型的数据，但主键必须是可哈希的类型。常见的可变类型，如列表、集合等都不能作为主键使用。即便是元组等不可变类型，也不能引用可变类型元素，即元组中不能含有可变类型的元素。 123456789101112&gt;&gt;&gt; import collections&gt;&gt;&gt; issubclass(list, collections.Hashable)False&gt;&gt;&gt; issubclass(int, collections.Hashable)True&gt;&gt;&gt; hash((1, 2, 3))2528502973977326415&gt;&gt;&gt; hash((1, 2, [1, 2])) # 包含可变类型Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: unhashable type: &apos;list&apos; 哈希计算通过调用 __hash__ 方法返回整数值，用来快速比较内容是否相同。某些类型虽然有该方法，但实际无法执行，故不能作为主键使用。另外，主键对象的哈希值必须恒定不变，否则无法查找键值，甚至会引发错误。12&gt;&gt;&gt; callable(list().__hash__)False 自定义类型默认实现了 __hash__ 和 __eq__ 方法，用与哈希和相等比较操作。前者为每个实例返回随机值；后者除非与自己比较，否则总是返回 False。这两个方法可根据需要进行重载。 作为常用的数据结构，又因为命名空间的缘故，字典的使用频率非常高。Python 开发团队也一直致力于改进其数据结构和算法，这其中自然也包括惯用的缓存复用。 Python 3.6 借鉴 PyPy 字典设计，采用更紧凑的存储结构。keys.entries 和 values 用数组按添加顺序存储主键和值引用。实际哈希表由 keys.indices 数组承担，通过计算主键哈希值找到合适的位置，然后在该位置存储主键在 key.entries 的实际索引。如此一来，只要通过 indices 获取实际索引后，就可读取主键和值信息了。 虽然该版本按添加顺序存储元素，但内部实现不能作为依赖条件。在后续版本中，可能有其他变化。如有明确顺序需求，建议使用 collections.OrderDict。 系统分别缓存复用 80 个 dict 和 keys，其中包括长度为 8 的 entries 内存。对于大量小字典对象而言，直接使用，无须任何内存分配操作。回收时，凡内存被扩张过的都会被放弃。 从开发地址法（open-address）实现方式来看，它并不适合处理大数据。轻量级方案可选用 shelve、dbm 等标准库模块，也可直接采用 SQLite、LevelDB 等专业数据库。 构建创建字典对象可以使用大括号键值对方式创建，或调用类型构造。1234&gt;&gt;&gt; &#123;&quot;a&quot;: 1, &quot;b&quot;: 2&#125;&#123;&apos;a&apos;: 1, &apos;b&apos;: 2&#125;&gt;&gt;&gt; dict(a=1, b=2)&#123;&apos;a&apos;: 1, &apos;b&apos;: 2&#125; 初始化键值参数也可以用元组、列表等可迭代对象的方式提供。123&gt;&gt;&gt; kvs = ((&quot;a&quot;, 1), [&quot;b&quot;, 2])&gt;&gt;&gt; dict(kvs)&#123;&apos;a&apos;: 1, &apos;b&apos;: 2&#125; 基于动态数据创建时，多以 zip、map 函数或推导式完成。123456&gt;&gt;&gt; dict(zip(&quot;abc&quot;, range(3)))&#123;&apos;a&apos;: 0, &apos;b&apos;: 1, &apos;c&apos;: 2&#125;&gt;&gt;&gt; dict(map(lambda k, v: (k, v + 10), &quot;abc&quot;, range(3)))&#123;&apos;a&apos;: 10, &apos;b&apos;: 11, &apos;c&apos;: 12&#125;&gt;&gt;&gt; &#123;k: v + 10 for k, v in zip(&quot;abc&quot;, range(3))&#125;&#123;&apos;a&apos;: 10, &apos;b&apos;: 11, &apos;c&apos;: 12&#125; 除了直接提供内容外，某些时候，还须根据一定条件初始化字典对象。比如，基于已有字典内容扩展，或初始化零值等。12345678910&gt;&gt;&gt; a = &#123;&quot;a&quot;: 1&#125;&gt;&gt;&gt; b = dict(a, b=1) # 在复制 a 内容的基础上，新增键值对&gt;&gt;&gt; b&#123;&apos;a&apos;: 1, &apos;b&apos;: 1&#125;&gt;&gt;&gt; c = dict.fromkeys(b, 0) # 仅用 b 的主键，内容另设&gt;&gt;&gt; c&#123;&apos;a&apos;: 0, &apos;b&apos;: 0&#125;&gt;&gt;&gt; d = dict.fromkeys((&quot;counter1&quot;, &quot;counter2&quot;), 0) # 显示提供主键&gt;&gt;&gt; d&#123;&apos;counter1&apos;: 0, &apos;counter2&apos;: 0&#125; 相比于 fromkeys 方法，推导式可完成更复杂的操作，比如额外的 if 过滤条件。 操作字典不是序列类型，不支持序号访问，可以使用主键（键值）读取、新增或删除内容。若主键（键值）不存在，会引发 KeyError 异常，可以先用 in、not in 语句判断是否存在该主键（键值），或用 get 方法返回默认值。 get 方法默认值参数仅返回，不影响字典内容。但某些时候，我们还须向字典插入默认值，比如用字典存储多个计数器，那么在第一次取值时延迟初始化很有必要。在字典内有零值内容代表该计数曾被使用，没有则无法记录该行为。12345678&gt;&gt;&gt; x = &#123;&#125;&gt;&gt;&gt; x.setdefault(&quot;a&quot;, 0) # 如果有 a，那么返回实际内容，否则新增&#123;a:0&#125;键值对0&gt;&gt;&gt; x&#123;&apos;a&apos;: 0&#125;&gt;&gt;&gt; x[&quot;a&quot;] = 100&gt;&gt;&gt; x.setdefault(&quot;a&quot;, 0)100 字典不支持加法、乘法、大小等运算，但可比较内容是否相同。12&gt;&gt;&gt; &#123;&quot;a&quot;: 1, &quot;b&quot;: 2&#125; == &#123;&quot;a&quot;: 1, &quot;b&quot;: 2&#125;True 视图与早期版本复制数据并返回列表不同，Python 3 默认以视图关联字典内容。如此一来，既能避免复制开销，还能同步观察字典变化。12345&gt;&gt;&gt; x = dict(a = 1, b = 2)&gt;&gt;&gt; ks = x.keys() # 主键视图&gt;&gt;&gt; for k in ks: print(k, x[k]) # 利用视图迭代字典a 1b 2 ::这一段代码不是很明白，迭代获取值还是从原来的字典中获取的，为什么会叫视图呢？:: 字典没有独立的只读版本，无论传递引用还是复制品，都存在弊端： 直接引用有被接收方修改内容的风险 复制品仅是一次快照，无法获知字典的变化 视图则不同，它能同步读取字典内容，却无法修改。且可选择不同粒度的内容进行传递，如此可将接收方限定为指定模式下的观察员。123def test(d): # 传递键值视图（items），只能读取，无法修改 for k, v in d: print(k, v) 视图还支持集合操作，以弥补字典功能上的不足。12345678910111213&gt;&gt;&gt; a = dict(a = 1, b = 2)&gt;&gt;&gt; b = dict(c = 3, b = 2)&gt;&gt;&gt; ka = a.keys()&gt;&gt;&gt; kb = b.keys()&gt;&gt;&gt; ka &amp; kb # 交集：在 a、b 中同时存在&#123;&apos;b&apos;&#125;&gt;&gt;&gt; ka | kb # 并集：在 a 或 b 中存在&#123;&apos;b&apos;, &apos;a&apos;, &apos;c&apos;&#125;&gt;&gt;&gt; ka - kb # 差集：仅在 a 中存在&#123;&apos;a&apos;&#125;&gt;&gt;&gt; ka ^ kb # 对称差集：仅在 a 或仅在 b 中出现，相当于“并集-交集”&#123;&apos;a&apos;, &apos;c&apos;&#125; 利用视图的集合运算，可简化某些操作。例如，只更新，不新增。12345678&gt;&gt;&gt; a = dict(a = 1, b = 2)&gt;&gt;&gt; b = dict(b = 20, c = 3)&gt;&gt;&gt; ks = a.keys() &amp; b.keys() # 交集，也就是 a 中必须存在的主键&gt;&gt;&gt; a.update(&#123;k: b[k] for k in ks&#125;) # 利用交集结果提取待更新的内容&gt;&gt;&gt; a&#123;&apos;a&apos;: 1, &apos;b&apos;: 20&#125; 拓展在标准库中，还有几个扩展类型的字典可供使用。 默认字典（defaultdict）类似于 setdefault 方法的包装。当主键不存在时，调用构造参数提供的工厂函数返回默认值。 将字典直接作为对外接口时，无法保证用户是否会调用 setdefault 或 get 方法。这样，默认字典的内置初始化行为就好于对用户做额外要求。1234567&gt;&gt;&gt; import collections&gt;&gt;&gt; d = collections.defaultdict(lambda : 100)&gt;&gt;&gt; d[&quot;a&quot;]100&gt;&gt;&gt; d[&quot;b&quot;] += 1&gt;&gt;&gt; ddefaultdict(&lt;function &lt;lambda&gt; at 0x10bfb4f28&gt;, &#123;&apos;a&apos;: 100, &apos;b&apos;: 101&#125;) 与内部实现无关，有序字典（OrderedDict）明确记录主键首次插入的次序。 任何时候都要避免依赖内部实现，或者说遵循“显式优于隐式”的规则。12345678&gt;&gt;&gt; d = collections.OrderedDict()&gt;&gt;&gt; d[&quot;z&quot;] = 1&gt;&gt;&gt; d[&quot;a&quot;] = 2&gt;&gt;&gt; d[&quot;x&quot;] = 3&gt;&gt;&gt; for k, v in d.items(): print(k, v)z 1a 2x 3 与前面所说不同，计数器（Counter）对于不存在的主键返回零，但不会新增，即将主键添加到字典中。 可通过继承并重载 __miss__ 方法新增键值123456&gt;&gt;&gt; d = collections.Counter()&gt;&gt;&gt; d[&quot;a&quot;]0&gt;&gt;&gt; d[&quot;b&quot;] += 1&gt;&gt;&gt; dCounter(&#123;&apos;b&apos;: 1&#125;) 链式字典（ChainMap）以单一接口访问多个字典内容，其自身并不存储数据。读操作按参数顺序依次查找各字典，但修改操作（新增、更新、删除）仅针对第一字典。12345678910111213141516&gt;&gt;&gt; a = dict(a = 1, b =2)&gt;&gt;&gt; a = dict(a = 1, b = 2)&gt;&gt;&gt; b = dict(b = 20, c = 30)&gt;&gt;&gt; x = collections.ChainMap(a, b)&gt;&gt;&gt; x[&quot;b&quot;], x[&quot;c&quot;] # 按顺序命中(2, 30)&gt;&gt;&gt; for k, v in x.items(): print(k, v) # 遍历所有字典b 2a 1c 30&gt;&gt;&gt; x[&quot;b&quot;] = 999 # 更新，命中第一字典&gt;&gt;&gt; x[&quot;z&quot;] = 888 # 新增，命中第一字典&gt;&gt;&gt; xChainMap(&#123;&apos;a&apos;: 1, &apos;b&apos;: 999, &apos;z&apos;: 888&#125;, &#123;&apos;b&apos;: 20, &apos;c&apos;: 30&#125;) 可利用链式字典设计多层次的上下文（context）结构。 合理的上下文类型，须具备两个基本特征。首先是继承，所有设置可被调用链的后续函数读取；其次是修改仅针对当前和后续逻辑，不应向无关的父级传递。如此，链式字典查找次序本身就是继承的体现，而修改操作被限制在当前第一字典中中，自然也不会影响父级字典的同名主键设置。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「Python3学习笔记」读书笔记—列表]]></title>
    <url>%2F2018%2F06%2F22%2F%E3%80%8CPython3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%8D%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E2%80%94%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[Python 中的 list 类型应该是我们平时用的最多一个数据类型，如果仅从操作方式上看，列表像是数组和链表的综合体，除了按索引访问外，还支持插入、追加、删除等操作，完全可以当作队列或栈来使用，因此，如果不考虑性能问题，列表是一种易用且功能完善的理想数据结构。 列表的内部结构由两部分构成：(1) 保存元素数量和内存分配计数的头部，(2) 存储元素指针的独立数组。所有的元素使用该数组来保存指针引用，并不嵌入实际的内容。 作为使用频率最高的数据结构之一，列表的性能优化很重要。固定长度的头部结构，很容易实现内存复用。创建时，优先从复用区获取；被回收时，除非超出复用数量限制（80），否则会被放回复用区。每次真正需要分配和释放的是指针数组。 用数组而非链表存储元素项引用，也有实际考虑。从读操作来看，无论是遍历还是基于序号访问，数组的性能总是最高的。尽管插入、删除等变更操作须移动内存，但也仅仅是指针复制，无论元素大小，不会有太高消耗。如果列表太大，或写操作远多于读操作，那么应该使用针对性的数据结构，而非通用设计的内置列表类型。 另外，指针数组内存分配算法基于元素数量和剩余空间大小，按相应比率进行扩容或收缩，非逐项进行。如此，可以避免太过频繁的内存分配操作。 构建列表显示指定元素的构建语法最为常用，也可基于类型创建实例，接收可迭代对象作为初始内容。不同于数组，列表仅存储指针，而对元素内容并不关心，故可以是不同类型混合。123456&gt;&gt;&gt; [1, &quot;abc&quot;, 3.14] # 显示指定类型[1, &apos;abc&apos;, 3.14]&gt;&gt;&gt; list(&quot;abc&quot;)[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;]&gt;&gt;&gt; list(range(3))[0, 1, 2] 另有被称为推导式（comprehension）的语法，同样使用方括号，但以 for 循环初始化元素，并可选用 if 表达式作为过滤条件。PS：一旦将推导式两边的方括号改为小括号，推导式就变成了生成器。12345678910111213141516&gt;&gt;&gt; [i for i in range(10)][0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; [i for i in range(10) if i % 2 == 0][0, 2, 4, 6, 8]&gt;&gt;&gt; (i for i in range(10) if i % 2 == 0) # 生成器&lt;generator object &lt;genexpr&gt; at 0x102216f10&gt;&gt;&gt;&gt; l = []# 推导式的行为等同与以下代码&gt;&gt;&gt; l = []&gt;&gt;&gt; for i in range(10):... if i % 2 == 0:... l.append(i)...&gt;&gt;&gt; l[0, 2, 4, 6, 8] 专有名词 Pythonic 的基本意思就是写出简洁优雅的 Python 代码，而推导式就算是其中的一种。 无论是历史原因，还是实现方式，内置类型关注性能要多过设计。如要实现自定义列表，书的作者建议基于 collections.UserList 包装类型来实现，因为除了统一的 collections.abc 体系外，最重要的是该类型重载并完善了相关运算符方法。123456789101112131415&gt;&gt;&gt; list.__bases__(&lt;class &apos;object&apos;&gt;,)&gt;&gt;&gt; import collections&gt;&gt;&gt; collections.UserList.__bases__(&lt;class &apos;collections.abc.MutableSequence&apos;&gt;,)# 以加法运算符为例，继承不同的类型，运算会有不同的结果&gt;&gt;&gt; class A(list): pass&gt;&gt;&gt; type(A(&quot;abc&quot;) + list(&quot;de&quot;))&lt;class &apos;list&apos;&gt;&gt;&gt;&gt; class B(collections.UserList): pass&gt;&gt;&gt; type(B(&quot;abc&quot;) + list(&quot;de&quot;))&lt;class &apos;__main__.B&apos;&gt; 最小接口设计是个基本原则，所以应该慎重考虑列表这种功能丰富的类型是否适合作为基类。 操作列表支持用加法连接多个列表，乘法运算符复制内容。但同是加法（或乘法）运算，但结果却不相同。123456789101112131415161718192021&gt;&gt;&gt; a = [1, 2]&gt;&gt;&gt; b = a&gt;&gt;&gt; a = a + [3, 4] # 新建列表，然后与 a 关联# a、b 结果不同，确定 a 指向新对象&gt;&gt;&gt; a[1, 2, 3, 4]&gt;&gt;&gt; b[1, 2]&gt;&gt;&gt; a = [1, 2]&gt;&gt;&gt; b[1, 2]&gt;&gt;&gt; b = a&gt;&gt;&gt; a += [3, 4] # 直接修改 a 内容# a、b 结果相同，确认修改原对象&gt;&gt;&gt; a[1, 2, 3, 4]&gt;&gt;&gt; b[1, 2, 3, 4]&gt;&gt;&gt; a is bTrue 编译器将 += 运算符处理成 INPLACE_ADD 操作，也就是修改原数据，而非新建对象。其效果类似于执行 list.extend 方法。PS：+= 运算符调用的是 __iadd__ 方法，没有该方法时，再尝试调用 __add__ 方法；+ 运算符调用的是 __add__ 方法，该方法会返回一个新的对象，原对象不修改。 判断元素是否存在，习惯使用 in，而非 index 方法。12&gt;&gt;&gt; 2 in [1, 2]True 至于删除操作，可用索引序号指定某个元素，或切片指定删除某个范围的元素。1234567&gt;&gt;&gt; a = [1, 2, 3, 4, 5]&gt;&gt;&gt; del a[4] # 删除单个元素&gt;&gt;&gt; a[1, 2, 3, 4]&gt;&gt;&gt; del a[1:3] # 删除某个范围内的元素&gt;&gt;&gt; a[1, 4] 通过切片的方式创建新的列表对象时，会复制相关的指针数据到新数组。除了所引用的目标相同外，对列表自身的修改（插入、删除等）互不影响。123456789&gt;&gt;&gt; a = [0, 2, 4, 6]&gt;&gt;&gt; b = a[:2]&gt;&gt;&gt; a[0] is b[0] # 复制引用，依然指向同一对象True&gt;&gt;&gt; a.insert(1, 1) # 对 a 列表操作，不会影响 b&gt;&gt;&gt; a[0, 1, 2, 4, 6]&gt;&gt;&gt; b[0, 2] 复制的是指针（引用），而非目标元素对象。对列表自身的修改互不影响，但对目标元素对象的修改是共享的。 利用 bisect 模块，可向有序列表插入元素。它使用二分法查找适合的位置，可以用来实现优先级队列或一致性哈希算法。12345678&gt;&gt;&gt; d = [0, 2, 4]&gt;&gt;&gt; import bisect&gt;&gt;&gt; bisect.insort_left(d, 1) # 插入新元素后，依然保持有序状态&gt;&gt;&gt; d[0, 1, 2, 4]&gt;&gt;&gt; bisect.insort_right(d, 3)&gt;&gt;&gt; d[0, 1, 2, 3, 4] 自定义复合类型，可通过重载比较运算符（ __eq__、__lt__ 等）实现自定义排序条件。 元组尽管两者并没有直接关系，但在操作方式上，元组可被当作列表的只读版本使用。 因元组是不可变类型，它的指针数组无须变动，故一次性完成内存分配。系统会缓存复用一定长度的元组内存（含指针数组）。创建时，按所需长度提取复用，没有额外的内存分配。从这一点上来看，元组的性能要好于列表。 Python 3.6 缓存复用长度在 20 以内的 tuple 内存，每种 2000 上限。123456# IPyton&gt;&gt;&gt; %timeit [1, 2, 3]53.7 ns ± 1.49 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)&gt;&gt;&gt; %timeit (1, 2, 3)12.9 ns ± 0.027 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each) 元组支持与列表类似的运算符操作，但不能修改，每次操作都是返回新的对象。12345678910111213&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; id(a)4529921800&gt;&gt;&gt; a += [4, 5]&gt;&gt;&gt; id(a)4529921800&gt;&gt;&gt; b = (1, 2, 3)&gt;&gt;&gt; id(b)4537321872&gt;&gt;&gt; b += (4, 5)&gt;&gt;&gt; id(b)4537253648 列表因为支持插入、删除等修改操作，所以序号无法与元素对象构成固定映射。但元组不同，相同序号总是返回同一对象，故可为序号取个“别名”(namedtuple)。123456789&gt;&gt;&gt; import collections&gt;&gt;&gt; User = collections.namedtuple(&quot;User&quot;, &quot;name,age&quot;) # 创建 User 类型，指定字段&gt;&gt;&gt; issubclass(User, tuple) # tuple 子类True&gt;&gt;&gt; user = User(&quot;Min&quot;, 22)&gt;&gt;&gt; user.name, user.age # 使用字段名访问(&apos;Min&apos;, 22)&gt;&gt;&gt; user[0] is user.name # 或依旧使用序号True 对于自定义纯数据类型，显然 namedtuple 要比 class 简介。关键在于，名字要比序号可读性更强并且更易维护，其类似于数字常量维护。 数组数组与列表、元组的本质区别在于：元素单一类型和内容嵌入。详细使用方式请看：8.7. array — Efficient arrays of numeric values1234567891011&gt;&gt;&gt; import array&gt;&gt;&gt; a = array.array(&quot;b&quot;, [0x11, 0x22, 0x33, 0x44])&gt;&gt;&gt; memoryview(a).hex() # 使用内存视图查看，内容嵌入而非指针&apos;11223344&apos;&gt;&gt;&gt; a = array.array(&quot;i&quot;)&gt;&gt;&gt; a.append(100)&gt;&gt;&gt; a.append(1.23)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: integer argument expected, got float 数组可直接存储包括 Unicode 字符在内的各种数字。 但复合类型须用 struct、marshal、pickle 等转换为二进制字节后再进行存储。 数组于列表类似，长度不固定，按需扩张或收缩内存。123456&gt;&gt;&gt; a = array.array(&quot;i&quot;, [1, 2, 3])&gt;&gt;&gt; a.buffer_info() # 返回缓冲区的内存地址和长度(4480106800, 3)&gt;&gt;&gt; a.extend(range(100000)) # 追加大量内容后，内存地址和长度发生变化&gt;&gt;&gt; a.buffer_info()(4487446528, 100003) 由于可指定更紧凑的数字类型，故数组可节约更多内存。再者，内容嵌入也避免了对象的额外开销，减少了活跃对象的数量和内存分配的次数。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「Python3学习笔记」读书笔记—字节数组]]></title>
    <url>%2F2018%2F06%2F21%2F%E3%80%8CPython3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%8D%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E2%80%94%E5%AD%97%E8%8A%82%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[生物都是由细胞构成的，但在我们普通人眼中，并不会将鸡、鸭、狗、鸟这些动物当作细胞看待，因为对待事物的角度决定了我们更关心生物的外在形状和行为，而不是它的组织构成。 从计算机底层实现来说，所有的数据都是二进制字节序列。但为了更好地表达某个逻辑，计算机科学家们将数据抽象成不同的类型，犹如细胞和动物的关系。在编程语言中，对于字节序列，我们更关心的是它的存储和传输方式；而面向对象时，则着重于它的抽象属性。尽管两面一体，但从不混为一谈。 同为不可变序列类型，bytes 与 str 有着非常相似的操作方式。其同样支持加法、乘法等运算符。12345678910111213&gt;&gt;&gt; a = b&quot;abc&quot;&gt;&gt;&gt; b = a + b&quot;def&quot;&gt;&gt;&gt; bb&apos;abcdef&apos;&gt;&gt;&gt; b.startswith(b&quot;a&quot;)True&gt;&gt;&gt; b.upper()b&apos;ABCDEF&apos;&gt;&gt;&gt; b&quot;abc&quot; * 2b&apos;abcabc&apos; 相比于 bytes 类型的一次性分配内存，bytearry 可按需扩张，更适合作为可读写缓冲区使用。如有必要，还可为其提前分配足够的内存，避免中途扩张造成的额外消耗。123456789&gt;&gt;&gt; b = bytearray(b&quot;abc&quot;)&gt;&gt;&gt; len(b)3&gt;&gt;&gt; id(b)4473445824&gt;&gt;&gt; b.append(ord(&quot;d&quot;))&gt;&gt;&gt; b.extend(b&quot;e&quot;)&gt;&gt;&gt; id(b)4473445824 内存视图当我们要引用字节数据的某个片段的时候，需要考虑到：是否会有数据复制行为？是否能同步修改？123456789&gt;&gt;&gt; a = bytearray([0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16])&gt;&gt;&gt; x = a[2:5] # 引用片段&gt;&gt;&gt; xbytearray(b&apos;\x12\x13\x14&apos;)&gt;&gt;&gt; a[3] = 0xEE # 修改原数据&gt;&gt;&gt; abytearray(b&apos;\x10\x11\x12\xee\x14\x15\x16&apos;)&gt;&gt;&gt; x # 并未同步修改，可以看出仅仅只是数据复制bytearray(b&apos;\x12\x13\x14&apos;) 为什么需要引用某个片段，而不是整个对象呢？ 以自定义网络协议为例，通常由标准头和数据体两部分组成。如要验证数据是否被修改，总不能将整个包作为参数交给验证函数吧。因为如果将整个包传给函数，这势必要求该函数了解协议包的结构，这显然是不合理的设计，而复制数据体又可能导致重大性能开销，同样得不偿失。 在 Python 中没有指针的概念，外加内存安全模型的限制，要做到这一点并不容易。此时，可以借助一种名为内存视图（Memory View）的方式来访问底层内存数据。 内存视图要求目标对象支持缓冲协议（Buffer Protocol），内存视图直接引用目标内存，没有额外的复制行为，因此，可读取最新的数据，在目标对象允许的情况下，还可以执行写操作。 123456789101112131415&gt;&gt;&gt; a = bytearray([0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16])&gt;&gt;&gt; v = memoryview(a) # 完整的视图&gt;&gt;&gt; x = v[2:5] # 视图片段&gt;&gt;&gt; x.hex()&apos;121314&apos;&gt;&gt;&gt; a[3] = 0xee # 对原数据进行修改，可通过视图观察到&gt;&gt;&gt; abytearray(b&apos;\x10\x11\x12\xee\x14\x15\x16&apos;)&gt;&gt;&gt; x.hex()&apos;12ee14&apos;&gt;&gt;&gt; x[1] = 0x13 # 因为引用了相同的内存区域，可通过视图修改原数据&gt;&gt;&gt; abytearray(b&apos;\x10\x11\x12\x13\x14\x15\x16&apos;) 当然，能够通过视图修改原数据，还必须得看原对象是否允许。123456&gt;&gt;&gt; a = b&quot;\x10\x11&quot; # bytes 是不可变类型&gt;&gt;&gt; v = memoryview(a)&gt;&gt;&gt; v[1] = 0xEETraceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: cannot modify read-only memory 如果要复制视图数据，可调用 tobytes、tolist 方法，复制后的数据与原对象无关，同样不会影响视图本身。1234567891011&gt;&gt;&gt; a = bytearray([0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16])&gt;&gt;&gt; v = memoryview(a)&gt;&gt;&gt; x = v[2:5]&gt;&gt;&gt; b = x.tobytes() # 复制并返回视图数据&gt;&gt;&gt; bb&apos;\x12\x13\x14&apos;&gt;&gt;&gt; a[3] = 0xEE # 对原数据进行修改&gt;&gt;&gt; abytearray(b&apos;\x10\x11\x12\xee\x14\x15\x16&apos;)&gt;&gt;&gt; b # 不影响复制数据b&apos;\x12\x13\x14&apos; 除了上述这些，内存视图还为我们提供了一种内存管理手段，比如：通过 bytearray 预申请很大的一块内存，随后以视图方式将不同片段交给不同的逻辑使用。因为逻辑不能跨界访问，故此可以实现简易的内存分配器模式。对于 Python 这种限制较多的语言，合理使用视图可在不同使用 ctypes 等复制扩展的前提下，改善算法类型。 可使用 memoryview.cast、struct.unpack 将字节数组转换为目标类型。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「Python3学习笔记」读书笔记—字符串]]></title>
    <url>%2F2018%2F06%2F14%2F%E3%80%8CPython3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%8D%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E2%80%94%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[字符串字面量以成对的单引号（`）、双引号（”），或可跨行的三引号（”””）语法构成，自动合并相邻的字面量。字符串支持转义、八进制、十六进制，或 Unicode 格式字符。 使用单引号还是双引号，并没有什么特殊限制。如果文本内的引用文字使用双引号，那么外面用单引号可避免转义，更易阅读。 通常情况下，建议遵循多数编程语言惯例，使用双引号标示。 Python 3 中字符串存储的是 Unicode 文本，是不可变序列类型。而 Unicode 格式大小写分别表示 16 位（ \u ）和 32 位（\U）整数，不能混用。12&gt;&gt;&gt; &quot;h\x69, \u6C49\U00005B57&quot;&apos;hi, 汉字&apos; 在字面量前添加标志，表示构建指定格式的字符串。1234&gt;&gt;&gt; type(u&quot;abc&quot;)&lt;class &apos;str&apos;&gt;&gt;&gt;&gt; type(b&quot;abc&quot;)&lt;class &apos;bytes&apos;&gt; 最常用的原始字符串（r, raw string），它将反斜线视作字符内容，而非转义标志。这在构建类似 Windows 路径、正则表达式匹配模式之类的文法字符串时很有用。 12345&gt;&gt;&gt; open(r&quot;c:\windows\readme.txt”)&gt;&gt;&gt; import re&gt;&gt;&gt; re.findall(r&quot;\b\d+\b&quot;, &quot;a10 100&quot;)[&apos;100&apos;] 操作字符串支持用加法或乘法运算符拼接字符串。12345&gt;&gt;&gt; s = &quot;hello&quot;&gt;&gt;&gt; s += &quot;, world&quot;&gt;&gt;&gt; &quot;-&quot; * 10&apos;----------&apos; 编译器会尝试在编译期直接计算出字面量拼接结果，可避免运行时的内存开销。不可此类优化程度有限，并不总是有效。1234567891011121314151617&gt;&gt;&gt; def test():... a = &quot;x&quot; + &quot;y&quot; + &quot;z&quot;... b = &quot;a&quot; * 10... return a, b...&gt;&gt;&gt; import dis&gt;&gt;&gt; dis.dis(test) 2 0 LOAD_CONST 7 (&apos;xyz&apos;) # 直接给出结果，省略加法结果 2 STORE_FAST 0 (a) 3 4 LOAD_CONST 8 (&apos;aaaaaaaaaa&apos;) # 省略乘法运算 6 STORE_FAST 1 (b) 4 8 LOAD_FAST 0 (a) 10 LOAD_FAST 1 (b) 12 BUILD_TUPLE 2 14 RETURN_VALUE 多个动态字符串拼接，应优先考虑 join 或 format 方式，而不是使用 + 号操作符直接拼接，这是因为相比于多次加法运算和多次内存分配（字符串是不可变对象），join 这类函数（方法）可预先计算出总长度，一次性分配内存，随后直接复制内存数据填充。另一方面，将固定模版内容与变量分离的 format，更易阅读和维护，可参考以前的这篇记录Python连接字符串优先使用join而不是+ | M-in’s Blog。 编写代码时除保持简单外，还应具备良好的可读性。比如：判断是否包含子字符串，in、not in 操作符就比 find 方法自然，更贴近日常阅读习惯。1234567&gt;&gt;&gt; &quot;py&quot; in &quot;python&quot;True&gt;&gt;&gt; &quot;py&quot; not in &quot;python&quot;False&gt;&gt;&gt; &quot;python&quot;.find(&quot;py&quot;)0 作为序列类型，可使用索引序号访问字符串的单个字符或某一片段（切片）。Python 3 支持负索引，也就是反向从尾部以 -1 开始（索引 0 表示正向第一个字符）。 123456789&gt;&gt;&gt; s = &quot;0123456789&quot;&gt;&gt;&gt; s[2]&apos;2&apos;&gt;&gt;&gt; s[-1]&apos;9&apos;&gt;&gt;&gt; s[2:6]&apos;2345&apos;&gt;&gt;&gt; s[2:-2]&apos;234567&apos; 无论以哪种方式返回与原字符串内容不同的子字符串时，都可能会重新分配内存，并复制数据。 转换除了与数字、Unicode 码点的转化外，最常见的是在不用编码间进行转换。Python 3 使用 bytes、bytearray 存储字节序列，不再和 str 混用。 格式化Python 3.6 新增了 f-strings 支持，这在多数脚本语言里属于标配。 使用 f 前缀标志，Python 解释器在解析大括号内的字段或表达式时，在上下文命名空间（namespace）查找同名对象进行值替换。 12345678&gt;&gt;&gt; x = 10&gt;&gt;&gt; y = 20&gt;&gt;&gt; f&quot;&#123;x&#125; + &#123;y&#125; = &#123;x + y&#125;&quot;&apos;10 + 20 = 30&apos;# 除运算符外，还可以是函数调用。&gt;&gt;&gt; f&quot;&#123;type(x)&#125;&quot;&quot;&lt;class &apos;int&apos;&gt;&quot; 完整的 format 格式化以位置序号或字段名匹配参数进行值替换，可添加对齐、填充、精度等控制。具体请参考官方文档6.1.3. Format String Syntax 池化因为无处不在的名字就是字符串实例，导致字符串可能是进程里实例数量最多的类型之一。 鉴于相同的名字会出现在不同的命名空间里，那么有必要共享实例。内容相同，且不可变，共享内存不会导致任何问题。关键是节约内存，且可省去创建新实例的开销。 对此，Python 的做法是实现一个字符串池（ intern ）。 池负责管理实例，使用者只需饮用即可。另一潜在的好处是，从池返回的字符串，只需比较指针就可知道内容是否相同，无需额外计算。可以使用池来提升哈希表等类似结构的查找性能。123&gt;&gt;&gt; import sys&gt;&gt;&gt; &quot;__name__&quot; is sys.intern(&quot;__name__&quot;)True 除以常量方式出现的名字和字面量外，动态生成的字符串一样可加入池中。如此可保证每次都引用同一对象，不会有额外的创建和分配操作。123456&gt;&gt;&gt; a = &quot;hello, world!&quot;&gt;&gt;&gt; b = &quot;hello, world!&quot;&gt;&gt;&gt; a is b # 不同实例False&gt;&gt;&gt; sys.intern(a) is sys.intern(&quot;hello, world!&quot;) # 相同实例True 当然，一旦失去所有外部引用，池内的字符串对象一样会被回收。123456789&gt;&gt;&gt; a = sys.intern(&quot;hello, world!&quot;)&gt;&gt;&gt; id(a)4318361584&gt;&gt;&gt; id(sys.intern(&quot;hello, world!&quot;)) # 有外部引用4318361584&gt;&gt;&gt; del a # 删除外部引用后被回收&gt;&gt;&gt; id(sys.intern(&quot;hello, world!&quot;)) # 从 id 值不同可以看到字符串是新建后入池的4318389808 字符串池的实现算法很简单，就是简单的字典结构。详细可参考 Objects/unicodeobject.c : PyUnicode_InternInPlace。做大数据处理时，可能须创建海量主键，使用类似机制有助于减少对象数量，节约大量内存。当然，可以选择更高效的数据结构，而不一定是系统内置的字符串池。 #读书笔记]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「Python3学习笔记」读书笔记--float类型]]></title>
    <url>%2F2018%2F06%2F09%2F%E3%80%8CPython3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E3%80%8D%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-float%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[本文为「Python3学习笔记」一书的读书总结，以后每学习完一小节做一次记录。 在Python中 float 类型默认存储双精度浮点数（也就是其他语言中的 double ），可一表达16到17位浮点数。 1234&gt;&gt;&gt; 1/30.3333333333333333&gt;&gt;&gt; 0.12345678901234567890.12345678901234568 从实现方式上来看，浮点数是以二进制的方式来存储十进制数的近似值。这就可能导致执行的结果与预期不符合，造成不一致缺陷。所以，在对精度有严格要求的场合，应该选择使用固定精度类型，如：decimal.Decimal 。 可通过 float.hex 方法输出实际存储值的十六进制格式的字符串，来查看执行结果为何不同；换句话说，也可以通过改方式实现浮点值的精确传递，避免精度丢失。 123456&gt;&gt;&gt; 0.1 * 3 == 0.3False&gt;&gt;&gt; (0.1 * 3).hex()&apos;0x1.3333333333334p-2&apos;&gt;&gt;&gt; (0.3).hex() # 显然两个存储的内容并不相同&apos;0x1.3333333333333p-2&apos; 123&gt;&gt;&gt; s = (1/3).hex()&gt;&gt;&gt; float.fromhex(s) # 反向转换回浮点数0.3333333333333333 对于简单的比较操作，可尝试将浮点数的精度限制在有效的精度内，如：使用 round函数，但round函数在实现上有一定的问题，这里更加准确的问题是使用 decimal.Decimal 模块。1234&gt;&gt;&gt; round(0.1 * 3, 2) == round(0.3, 2)True&gt;&gt;&gt; round(0.1, 2) * 3 == round(0.3, 2)False decimal.Decimal模块与 float 这种基于硬件的二进制浮点类型相比，decimal.Decimal 是用十进制实现的，它能准确的表达十进制数和运算，不存在二进制相似值的问题，它最高可提供28位有效精度。 12345&gt;&gt;&gt; (0.1 + 0.1 + 0.1 - 0.3) == 0 # 二进制近似值计算结果与十进制预期不符合False&gt;&gt;&gt; from decimal import Decimal&gt;&gt;&gt; (Decimal(&apos;0.1&apos;) + Decimal(&apos;0.1&apos;) + Decimal(&apos;0.1&apos;) - Decimal(&apos;0.3&apos;)) == 0True 而在创建 Decimal 实例的时候，应该传入一个准确数值，如：整数或者字符串等。如果传入的是 float 类型，那么在传入之前，其精度就已经丢失了。 1234&gt;&gt;&gt; Decimal(0.1)Decimal(&apos;0.1000000000000000055511151231257827021181583404541015625&apos;)&gt;&gt;&gt; Decimal(&apos;0.1&apos;)Decimal(&apos;0.1&apos;) 在需要的时候，可以通过上下文修改 Decimal 默认的28位精度或用 localcontext修改某个区域的精度。 12345678910111213141516171819&gt;&gt;&gt; from decimal import Decimal, getcontext, localcontext&gt;&gt;&gt; getcontext()Context(prec=28, ...)&gt;&gt;&gt; getcontext().prec = 2&gt;&gt;&gt; Decimal(1) / Decimal(3)Decimal(&apos;0.33&apos;)&gt;&gt;&gt; with localcontext() as ctx:... print(getcontext().prec)... getcontext().prec = 3... print(getcontext().prec)... print(Decimal(1) / Decimal(3))...230.333&gt;&gt;&gt; getcontext().prec2 Decimal 虽然有着准确的精度，但它的运算速度会慢很多，所以除非有明确的需求，否则还是不要用 Decimal 代替 float 是用。 round 函数因为精度和近似值问题，在使用round函数对 float 类型的值进行“四舍五入”的操作存在不确定性，结果会有一些不易察觉的陷阱。1234&gt;&gt;&gt; round(0.5) # 五舍0&gt;&gt;&gt; round(1.5) # 五入2 这是因为round函数的算法规则是按临近的数字的距离远近来考虑是否进位的，如：以 0.4 为例，其舍入后相邻的数字分别是 0 和 1 ，从距离上来看自然是离 0 更近一些，所以“四舍五入”的结果为 0。如此一来，“四舍六入”就是确定的，相关问题都集中在两边距离相等的5是否进位上了。 对于5是否进位，首先要考虑的是它后面是否还有小数位。如果有，那么左右距离自然是不想等的，这种情况肯定是会进位的。1234&gt;&gt;&gt; round(0.5)0&gt;&gt;&gt; round(0.500001)1 如果没有，就要看进位后是整数还是浮点数了。如果是整数，就取临近的偶数。1234&gt;&gt;&gt; round(0.5)0&gt;&gt;&gt; round(1.5)2 不同的Python版本，规则存在着差异性，如：在Python2.7中，round(2.5) 返回的是3.0。 而进位后，如果依旧是浮点数的话，那事情就变得有点莫名其妙了。有的文章中说的是要看数字5前一位小数的奇偶行来判断是否进位，而事实上并非如此。12345678&gt;&gt;&gt; round(1.25, 1) # 偶舍1.2&gt;&gt;&gt; round(1.245, 2) # 偶入1.25&gt;&gt;&gt; round(2.675, 2) # 下面都是奇数7，但却有舍有进2.67&gt;&gt;&gt; round(2.375, 2)2.38 对此，Python官方文档Floating Point Arithmetic: Issues and Limitations宣称着并非错误，而是事出有因。我们可以改用 Decimal ，按需选取可控的进位方案。 转换在 Python 中将整数或字符串转换为浮点数很简单，而且 Python 还会自动处理字符串内的正负号和空白符。只是超出有效精度时，结果与字符串内容存在差异。12345678910&gt;&gt;&gt; float(100)100.0&gt;&gt;&gt; float(&apos;-100.123&apos;)-100.123&gt;&gt;&gt; float(&apos;\t -100.123\n&apos;)-100.123&gt;&gt;&gt; float(&apos;1.23E2&apos;)123.0&gt;&gt;&gt; float(&apos;0.12345678901234567890&apos;) # 超出精度0.12345678901234568 反过来，将浮点数转换为整数时，有多种方案可供选择。 可直接截掉小数部分 123456&gt;&gt;&gt; int(2.6), int(-2.6)(2, -2)&gt;&gt;&gt; from math import trunc&gt;&gt;&gt; trunc(2.6), trunc(-2.6)(2, -2) 分别向大小两个方向取临近整数 12345&gt;&gt;&gt; from math import floor, ceil&gt;&gt;&gt; floor(2.6), floor(-2.6) # 向小数字方向取最近整数(2, -3)&gt;&gt;&gt; ceil(2.6), ceil(-2.6) # 向大数字方向取最近整数(3, -2)]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018年5月27日 个人思考]]></title>
    <url>%2F2018%2F05%2F27%2F2018%E5%B9%B45%E6%9C%8827%E6%97%A5-%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[最近因为临近毕业了，在学校做毕业答辩准备，顺带有时间可以思考一下工作以来的生活。 怎么说呢，相对上一份工作的硬性规定九九六，现在所在公司的工作时间是真的很轻松，每天6点就可以下班，也不需要加班，这样的生活虽然工资不高但真的很轻松，也使我陷入了一种舒适区，若不是这次回学校思考后，幡然醒悟，不然还不知道要在这种状态下沉迷多久。 先记录一下每天安排： 上午，高级工程师安排工作，编码、调试、解Bug，下班，然后回家刷刷微博，锻炼锻炼，看看电影，周末睡个懒觉，下午看看书或者出去玩一下，周一再去上班…… 今天结束回想起昨天的事，会发现并没有什么差别，这一周与上一周相似，这个月和上个月相似…… 越发觉得自己就像个没有灵魂的机器似的…… 用程序来描述的话，就是下面这样：12while True: 平淡无奇地混过今天() 上面的代码就是个死循环，永远跳不出来。 再加上这几天和一个考研的同学聊天，发现舒适区真的挺可怕的，有时候不逼自己一把，想要有所突破真的很困难。 有时候，真的很想做一条咸鱼，就这样堕落下去算了。但一想到自己对物质的欲望，就放弃了，贫穷限制了我做咸鱼的梦想。 喜欢张一鸣的说的「所谓成功，就是延迟满足」，谁不想享受现在，对以后不管不顾呢，现在逼自己学习，逼自己吃苦，是为了以后更好的满足。 敬：不甘平凡的人们！]]></content>
      <categories>
        <category>反思</category>
      </categories>
      <tags>
        <tag>反思</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python连接字符串优先使用join而不是+]]></title>
    <url>%2F2018%2F02%2F28%2FPython%E8%BF%9E%E6%8E%A5%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%BC%98%E5%85%88%E4%BD%BF%E7%94%A8join%E8%80%8C%E4%B8%8D%E6%98%AF%2F</url>
    <content type="text"><![CDATA[字符串处理在大多数编程语言中都是不可避免的，而字符串的连接在编程的过程中会经常遇到。Python 中的字符串与其他语言的字符串有点不一样，如：C++，Java，在 Python 中字符串是不可变对象，创建之后便不可以修改了，因此，这个特性会影响到字符串在连接时的效率问题。 常用的字符串连接方法 使用操作符+连接字符串： 1234In [1]: str1, str2, str3 = &apos;string1 &apos;, &apos;string2 &apos;, &apos;string3 &apos;In [2]: str1 + str2 + str3Out[2]: &apos;string1 string2 string3&apos; 使用join方法连接字符串： 1234In [1]: str1, str2, str3 = &apos;string1 &apos;, &apos;string2 &apos;, &apos;string3 &apos;In [2]: &apos;&apos;.join([str1, str2, str3])Out[2]: &apos;string1 string2 string3&apos; 上述两种方式产生了相同的结果，那么除了形式不同外，它们的效率是否一样呢？ 性能测试123456789101112131415161718192021222324import timeit# 100000是字符串连接数目，对应后面的测试数据str_list = ['this is a long string used for testing.' for n in range(100000)]# 使用 join 方法连接 str_list 中的元素def join_test(): return ''.join(str_list)# 使用 + 进行字符串连接def plus_test(): result = '' for item in str_list: result = result + item return resultif __name__ == '__main__': join_timer = timeit.Timer('join_test()', 'from __main__ import join_test') print(join_timer.timeit(100)) plus_timer = timeit.Timer('plus_test()', 'from __main__ import plus_test') print(plus_timer.timeit(100)) 给上述代码传入一组测试参数（10，100，1000，10000，100000），用于测试join_test()和plus_test()这两个方法在进行字符串连接时所用时间的变化，分别记录每次测试的结果： 连接的字符串数量 join_test()运行时间 plus_test()运行时间 10 4.9165013479068875e-05 0.00016158400103449821 100 0.00013869800022803247 0.001382818998536095 1000 0.0009924670157488436 0.015010426985099912 10000 0.01003621399286203 0.16328153299400583 100000 0.08696807900560088 1.762425111985067 结果分析从测试结果可以看到使用join()方法和使用+操作符来连接字符串时，join()方法的效率明显要高于+操作符。那么，造成这种差别的原因在哪里呢？ 在使用+操作符时，由于字符串是不可变对象，其工作原理应该是这样：如果要连接如下字符串时：s1 + s2 + s3 + …… + sn，执行一次+操作便会在内存中申请一块新的内存空间，并将上次操作的结果和本次操作的右操作数复制到新申请的内存空间，即当执行 s1 + s2 时，会申请一块内存空间，将 s1、s2 复制到该内存中，执行 s1 + s2 + s3 时，会申请一块内存空间，将 s1 + s2 的结果和 s3 复制到该内存中，依次类推。在 N 个字符串的连接过程中，会产生N-1个中间结果，每一个中间结果都要申请和复制一次内存，因此严重的影响了执行效率。 而当用joio()方法连接字符串时，会先计算出需要的总的内存空间，然后一次性申请内存空间并将字符串复制到申请的内存空间中，减少了中间结果，所以执行效率较高。 因此，在字符串的连接过程中，特别是大规模字符串的连接，应该优先使用join而不是+。因水平有限，以上分析说的不对还请指出。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>字符串连接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python虚拟环境Virtualenv和Virtualenvwrapper搭建]]></title>
    <url>%2F2018%2F02%2F24%2FPython%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83Virtualenv%E5%92%8CVirtualenvwrapper%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[virtualenv 是一个创建隔绝的Python环境的 Python 包。当我们遇到几个项目依赖不同版本的包的时候，如：项目A需要 Django 1.10 版本，项目B需要 Django 1.11 版本，这时就可以使用 virtualenv 来解决这个问题。 Virtualenv安装virtualenv1pip install virtualenv 使用方法123mkdir your_project_foldercd your_project_foldervirtualenv env # env是你的虚拟环境名称 此时会建立一个带有系统 Python 环境中所有第三方包的 Python 运行环境，若不想带有这些第三方包，命令中加上--no-site-packages这个参数，就可以得到一个不带有任何第三包的“纯净”的 Python 运行环境。1virtualenv --no-site-packages [虚拟环境名] 并且，在创建虚拟 Python 运行环境时，还可以通过-p参数指定 Python 解释器： 1virtualenv -p /usr/bin/python3 [虚拟环境名] 激活虚拟环境1source env/bin/activate 运行此命令后，会发现命令提示符前多了一个(env)的前缀，这表明当前环境是一个名为 env 的 Python 运行环境。 退出虚拟环境1deactivate 若不想要该虚拟运行环境了，直接使用rm -rf [虚拟环境名]命令删除即可(简单粗暴)。 Virtualenvwrappervirtualenvwrapper 是 virtualenv 的扩展管理包，virtualenvwrapper提供了一系列命令让虚拟环境在使用时变得愉快许多，它把您所有的虚拟环境都放在一个地方。 安装1pip install virtualenvwrapper 安装完成后，还需要运行 virtualenvwrapper.sh 文件才使用 virtualenvwrapper，该文件通常情况下是在/usr/local/bin/目录下，但有时发生意外情况就需要查找该文件了： 1find / -name virtualenvwrapper.sh 该文件中写有安装步骤，按照步骤把环境设置好即可。 12345678910111213141516# Setup:## 1. Create a directory to hold the virtual environments.# (mkdir $HOME/.virtualenvs).# 2. Add a line like "export WORKON_HOME=$HOME/.virtualenvs"# to your .bashrc.# 3. Add a line like "source /path/to/this/file/virtualenvwrapper.sh"# to your .bashrc.# 4. Run: source ~/.bashrc# 5. Run: workon# 6. A list of environments, empty, is printed.# 7. Run: mkvirtualenv temp# 8. Run: workon# 9. This time, the "temp" environment is included.# 10. Run: workon temp# 11. The virtual environment is activated. 首先是创建一个目录来存放未来创建的所有虚拟环境： 1mkdir $HOME/.virtualenvs # 目录名随意，这里用的是.virtualenvs 在.bashrc(bash) 或者.zshrc(zsh)，根据使用的shell来定，添加： 123export WORKON_HOME=$HOME/.virtualenvsexport VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3 # 设置虚拟环境默认Python解释器版本，可省略source /path/to/this/file/virtualenvwrapper.sh 激活 shell 配置文件： 1source .bashrc 或者 source .zshrc 使用查看虚拟环境列表1workon 或者 lsvirtualenv 创建虚拟环境1mkvirtualenv [虚拟环境名] 启动/切换虚拟环境1workon [虚拟环境名] 删除虚拟环境1rmvirtualenv [虚拟环境名] 退出虚拟环境1deactivate]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派搭建简单的 Nginx + uWSGI + Django]]></title>
    <url>%2F2018%2F02%2F24%2F%E6%A0%91%E8%8E%93%E6%B4%BE%E6%90%AD%E5%BB%BA%E7%AE%80%E5%8D%95%E7%9A%84%20Nginx%20%2B%20uWSGI%20%2B%20Django%2F</url>
    <content type="text"><![CDATA[当我们编写完成 Django 项目后，可以使用python manager.py runserver来运行 Django 自带的服务器，但这只适合于测试环境使用，项目正式上线时，我们需要一个可以稳定并且持续的服务器，比如Apache, Nginx等。手里吃灰很久的树莓派终于可以派上用场了😂。 准备工作 烧写好系统的树莓派，我这里使用的是基于 Debian 的 Raspbian 系统，理论上后续搭建步骤在 Ubuntu/Debian 上都可以用。 注意 2016 年 11 月的新版本系统之后，树莓派默认禁用 SSH，你需要手动开启。如果没有屏幕，则在boot分区的根目录下创建一个名为 ssh 的文件即可开启 安装Nginx1sudo apt install nginx 安装完成后 nginx 服务器默认就启动了。 nginx 相关命令： 123sudo service nginx start # 启动 nginxsudo service nginx stop # 停止 nginxsudo service nginx restart # 重启 nginx 安装uWSGI1pip install uwsgi 测试 uWSGI 是否正常： 建立一个 test.py 文件，内容如下： 123def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return "Hello World" 然后在命令行运行以下命令： 1uwsgi --http :8000 --wsgi-file test.py --http :8000：表示使用的是 http 协议，端口号为8000 --wsgi-file test.py：表示要运行的 wsgi 应用程序文件 更多参数使用请看：uWSGI 参数详解 uwsgi 命令运行后，在浏览器访问[服务器IP地址]:8000，若看到Hello World则表明 uWSGI 运行正常。 uWSGI配置uWSGI 支持 ini、xml 等多种配置方式，这里以 ini 配置为例。在/var/www/html/[项目名]目录下创建一个 mysite_uwsgi.ini 文件，内容如下： 1234567891011121314151617181920212223[uwsgi]# Django-related settings# the base directory (full path)chdir = /var/www/html/your_project_name# Django's wsgi filemodule = your_project_name.wsgi# the virtualenv (full path)home = /path/to/virtualenv# process-related settings# mastermaster = true# maximum number of worker processesprocesses = 10# the socket (use the full path to be safesocket = :8000# ... with appropriate permissions - may be needed# chmod-socket = 664# clear environment on exitvacuum = true# background the process &amp; logdaemonize = /var/www/html/your_project_name/uwsgi.logpidfile = /tmp/uwsgi.pid 然后就可以使用配置文件的方式来使用 uWSGI ： 1uwsgi --ini mysite_uwsgi.ini nginx配置新建一个名为mysite_nginx.conf的文件，内容如下： 12345678910111213141516171819202122232425262728293031323334# mysite_nginx.conf# the upstream component nginx needs to connect toupstream django &#123; # server unix:///path/to/your/mysite/mysite.sock; # for a file socket server 127.0.0.1:8000; # for a web port socket (we&apos;ll use this first)&#125;# configuration of the serverserver &#123; # the port your site will be served on listen 80; # the domain name it will serve for server_name .example.com; # 替换为你的机器的IP地址或者FQDN charset utf-8; # max upload size client_max_body_size 75M; # adjust to taste # Django media location /media &#123; alias /path/to/your/mysite/media; # your Django project&apos;s media files - amend as required &#125; location /static &#123; alias /path/to/your/mysite/static; # your Django project&apos;s static files - amend as required &#125; # Finally, send all non-media requests to the Django server. location / &#123; uwsgi_pass django; include /etc/nginx/uwsgi_params; # the uwsgi_params file you installed &#125;&#125; 替换完成文件中的相关文件路径后，在/etc/nginx/sites-enabled目录下，建立该文件的符号链接： 1sudo ln -s ~/[你的文件所在路径]/mysite_nginx.conf /etc/nginx/sites-enabled/ 重启 nginx 服务器： 1sudo service nginx restart 最后，将 uWSGI 运行起来，就看到你的 Django 项目已经跑起来了。 参考文章： Setting up Django and your web server with uWSGI and nginx]]></content>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的__init__、__new__和__call__]]></title>
    <url>%2F2018%2F02%2F01%2FPython%E4%B8%AD%E7%9A%84-init-%E3%80%81-new-%E5%92%8C-call%2F</url>
    <content type="text"><![CDATA[__init__、__new__和__call__方法都是python中的魔术方法，通常我们认为__init__方法是类的构造方法，因为表面上看确实是这样：当需要实例化一个对象的时候，使用a = Class(args...)便可以返回一个类的实例，其中args参数与__init__中申明的参数一样，今天在刘志军老师的「Python之禅和朋友们」的知识星球中学习到不是这样的，这里以一个例子来说明一下：123456789101112131415161718192021222324252627class A: def __new__(cls, *args, **kwargs): print('__new__') print(cls) print(args) print('-------') return super(A, cls).__new__(cls) def __init__(self): print('__init__') print('self is ', self) self.a, self.b = a, ba = A(1, 2)print(a.a)输出：__new__&lt;class '__main__.A'&gt;(1, 2)-------__init__Traceback (most recent call last): File "test.py", line 14, in &lt;module&gt; a = A(1, 2)TypeError: __init__() takes 1 positional argument but 3 were given 可以看到这里我们并没有直接调用__new__方法，却先产生了__new__方法的输出并抛出了异常，所以说__init__并不是真正意义上的构造方法，__init__所做的工作是在类的对象创建好之后进行变量的初始化。__new__方法才会真正创建实例，是类的构造方法。 call方法又是干嘛的呢？ Python官方文档中是这样写的：Called when the instance is “called” as a function; if this method is defined, x(arg1, arg2, …) is a shorthand for x.call(arg1, arg2, …). 即实现了__call__方法的对象的实例就可以像方法、函数一样的被调用执行123456789class A: def __call__(self, *args, **kwargs): print('__call__')a = A()a()输出：__call__]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Packet Tracer 模拟一次完整的HTTP请求]]></title>
    <url>%2F2018%2F02%2F01%2FPacket%20Tracer%20%E6%A8%A1%E6%8B%9F%E4%B8%80%E6%AC%A1%E5%AE%8C%E6%95%B4%E7%9A%84HTTP%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[Q：当我们在浏览器中访问一个网址的时候 ，浏览器背后到底发生了什么呢？A：DNS域名解析 –> 发起TCP的3次握手 –> 建立TCP连接后发起http请求 –> 服务器响应http请求，浏览器得到html代码 –> 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） –> 浏览器对页面进行渲染呈现给用户 –> 进行TCP的4次挥手 这里我在Packet Tracer中模拟一次简单的HTTP请求 环境准备网络拓扑图如下： 域名解析首先浏览器会向DNS服务器发送DNS数据包，请求访问域名所对应的IP地址，这里以在PC1中的浏览器访问www.test.com为例。模拟模式中可以看到PC1产生的DNS数据包以及DNS服务器响应的数据包： 发起TCP的三次握手得到域名对应的IP地址之后，浏览器会向web服务器发起TCP连接请求，web服务器收到请求后发出响应，过程如下：TCP数据包内容如下： 建立TCP连接后发起http请求经过TCP的3次握手之后，浏览器发起了http的请求，使用的http的方法 GET 方法，请求的URL是 / ,协议是HTTP/1.1 服务器端响应http请求，浏览器得到html代码服务器端WEB程序接收到http请求以后，就开始处理该请求，处理之后就返回给浏览器html文件。 浏览器解析html代码，并请求html代码中的资源浏览器拿到服务器返回的html文件后，就开始解析其中的html代码，遇到js/css/image等静态资源时，就向服务器端去请求下载。 浏览器对页面进行渲染呈现给用户这里的html很简单就只有一行文本 进行TCP的4次挥手当数据传送完毕，浏览器会发起断开连接请求，这就有了TCP的4次挥手的过程。 这里不知道是Packet Tracer版本还是其他什么问题，服务器在收到客户端断开连接请求的时候，只发了FIN+ACK的TCP数据包，没有先发送含有ACK的TCP数据包。 至此就完成了一次简单的HTTP请求，这里只是简单的描述一下，实际中要比模拟出来的复杂很多。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的可变对象与不可变对象]]></title>
    <url>%2F2018%2F01%2F25%2FPython%E4%B8%AD%E7%9A%84%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1%E4%B8%8E%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[Python中一切皆为对象，每一个对象都有一个唯一的标识符（ id( ) ）、类型（type( )）以及值。而对象根据其值是否能够修改分为可变对象和不可变对象： 数字、字符串和元组属于不可变对象 字典、列表和字节数组属于可变对象 对于不可变对象，任何对其中的元素进行修改的操作都会抛出异常。12345678910111213141516171819&gt;&gt;&gt; test_str = 'hello world'&gt;&gt;&gt; test_str[5] = 'q'-----------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-2-8e9684bd3ddc&gt; in &lt;module&gt;()&gt; 1 test_str[5] = 'q'TypeError: 'str' object does not support item assignment&gt;&gt;&gt; test_tuple = (1, 2, 3)&gt;&gt;&gt; test_tuple[1] = 4-----------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-4-dba7800e3210&gt; in &lt;module&gt;()&gt; 1 test_tuple[1] = 4TypeError: 'tuple' object does not support item assignment 而对于可变对象，对其进行操作需要考虑到浅拷贝和深拷贝的问题。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的浅拷贝与深拷贝]]></title>
    <url>%2F2018%2F01%2F25%2Fpython%E4%B8%AD%E7%9A%84%E6%B5%85%E6%8B%B7%E8%B4%9D%E4%B8%8E%E6%B7%B1%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[在面试过程中，经常会被问浅拷贝与深拷贝的区别。所以，在这里记录一下自己的理解，以便以后好复习。 浅拷贝（shallow copy）所谓“浅拷贝”，是指在复制一个对象时，构建一个新的对象，并将原对象中发现的引用插入到该对象中. 浅拷贝的实现方式常见的有：工厂函数、切片操作、copy模块中的copy函数等实现如下：1234567891011121314151617&gt;&gt;&gt; a = [1, 2, [3, 4]]&gt;&gt;&gt; b = a[:]&gt;&gt;&gt; id(a)4505384008&gt;&gt;&gt; id(b)4504586056&gt;&gt;&gt; [id(x) for x in a][4470102640, 4470102672, 4505384072]&gt;&gt;&gt; [id(x) for x in b][4470102640, 4470102672, 4505384072]&gt;&gt;&gt; a[2] += [5]&gt;&gt;&gt; a[1, 2, [3, 4, 5]]&gt;&gt;&gt; b[1, 2, [3, 4, 5]] 从上面可以看出，a和b指向内存中不同的list对象，但它们的元素却指向相同的对象，此时操作 a 中的元素，b 中的元素也会跟着一起改变。 深拷贝（deep copy）所谓“深拷贝”，是指在复制一个对象时，也构建一个新的对象，但是在遇到引用会继续递归拷贝其所指向的具体内容，也就是说构建出来的新的对象不会收到其他引用对象操作的影响。 深拷贝的实现方式：使用copy模块中的deepcopy()函数1234567891011121314151617&gt;&gt;&gt; import copy&gt;&gt;&gt; a = [1, 2, [3, 4]]&gt;&gt;&gt; b = copy.deepcopy(a)&gt;&gt;&gt; id(a)4424991880&gt;&gt;&gt; id(b)4424991688&gt;&gt;&gt; [id(x) for x in a][4416637552, 4416637584, 4424992072]&gt;&gt;&gt; [id(x) for x in b][4416637552, 4416637584, 4424991752]&gt;&gt;&gt; a[2] += [5]&gt;&gt;&gt; print(a)[1, 2, [3, 4, 5]]&gt;&gt;&gt; print(b)[1, 2, [3, 4]] 这里可能会产生一个疑惑，为什么使用了深拷贝，a 和 b 中的元素有些还是一样呢？ 这是因为对于不可变对象，当需要一个新的对象时，python可能会返回已经存在的某个类型和值都一致的对象的引用。而且这种机制并不会影响 a 和 b 的相互独立性，因为当两个元素指向同一个不可变对象时，对其中一个赋值不会影响另外一个。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>浅拷贝</tag>
        <tag>深拷贝</tag>
      </tags>
  </entry>
</search>
